{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intermediate Slurm on Milton\n",
    "### Delivered by WEHI Research Computing Platform\n",
    "\n",
    "<pre>Edward Yang    Michael Milton    Julie Iskander</pre><br>\n",
    "\n",
    "<img src=\"static/1200px-Slurm_logo.svg.png\" alt=\"Slurm\" width=\"100\"/>\n",
    "<img src=\"static/milton.png\" alt=\"Milton Mascot\" width=\"100\"/>\n",
    "<img src=\"static/WEHI_RGB_logo.png\" alt=\"WEHI logo\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [OPTIONAL SLIDE] Self Introductions!\n",
    "\n",
    "### Me\n",
    "* Civil Engineer by training\n",
    "* HPC by interest\n",
    "* Mostly code in Fortran, occasionally Python\n",
    "* I use HPC to simulate fluid and granular flows\n",
    "\n",
    "## How about you?\n",
    "* name\n",
    "* How you use Milton's HPC\n",
    "* Your coffee/tea order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background\n",
    "* We already ran an \"intro to Slurm\" workshop (recording on RCP website)\n",
    "* More \"advanced\" features of Slurm were highly requested\n",
    "* Both ITS and researchers would benefit\n",
    "    * ITS will have fewer issues to address\n",
    "    * researchers can accelerate their research <- High Priority for everyone!\n",
    "\n",
    "### Target Audience\n",
    "* You've submitted quite a few jobs via `sbatch`\n",
    "* You're familiar with resource requests. Like:\n",
    "    * using `--ntasks` and `--cpus-per-task`\n",
    "    * using `--mem` and/or `--memory-per-cpu`\n",
    "* You're wondering whether your jobs are utilizing resources efficiently\n",
    "* You're wondering how to make your life easier when using `sbatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Background cont.\n",
    "\n",
    "My goal for the session is to teach you how to:\n",
    "* get the status of the cluster\n",
    "* get information about your jobs\n",
    "* make use of `sbatch` scripting features\n",
    "* Run emabarrasingly parallel tasks\n",
    "* **bonus topic** submitting jobs from R or submitting `python` or `R` scripts without a wrapper script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda for Today\n",
    "\n",
    "12:00 - 12:30&emsp;<span style=\"color:blue\">Introduction & Housekeeping</span>\n",
    "\n",
    "12:30 - 13:00&emsp;Lunch\n",
    "\n",
    "13:00 - 13:30&emsp;Laying the groundwork: nodes, tasks and other Slurm terminology\n",
    "\n",
    "13:30 - 14:00&emsp;Understanding your jobs and the job queue\n",
    "\n",
    "13:30 - 14:00&emsp;Basic profiling of your jobs\n",
    "\n",
    "14:00 - 14:30&emsp;Slurm scripting features\n",
    "\n",
    "14:30 - 15:00&emsp;Embarrarsingly parallel examples\n",
    "\n",
    "15:00 - 15:30&emsp;R batchtools\n",
    "\n",
    "15:30 - 16:00&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction and Housekeeping\n",
    "\n",
    "### Format\n",
    "Slides + live coding\n",
    "\n",
    "Live coding will be on Milton, so make sure you're connected to WEHI's VPN or staff network, or use RAP:<br />\n",
    "rap.wehi.edu.au\n",
    "\n",
    "Please follow along to reinforce learning!\n",
    "\n",
    "Questions:\n",
    "* Put your hand up whenever you have a question or have an issue running things\n",
    "* Questions in the chat are welcome and will be addressed by helpers\n",
    "\n",
    "Material is available here:\n",
    "/link\n",
    "\n",
    "Feel free to download the notebook and follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction and Housekeeping Cont.\n",
    "### Expected understanding of\n",
    "* <span style=\"font-size:1.2em;\">Concept of \"resources\"</span><br />\n",
    "`CPUs`<br />\n",
    "`RAM/memory`<br />\n",
    "`Nodes`<br /><br />\n",
    "* <span style=\"font-size:1.2em;\">Job submission commands</span><br />\n",
    "`srun    # executes a command/script/binary across tasks`<br />\n",
    "`salloc  # allocates resources to be used (interactively and/or via srun)`<br />\n",
    "`sbatch  # submits a script for later execution on requested resources`<br /><br />\n",
    "* <span style=\"font-size:1.2em;\">resource request options</span><br />\n",
    "`--ntasks=             # \"tasks\" recognised by srun`<br />\n",
    "`--nodes=              # no. of nodes`<br />\n",
    "`--ntasks-per-node=    # tasks per node`<br />\n",
    "`--cpus-per-task=      # cpus per task`<br />\n",
    "`--mem=                # memory required for entire job`<br />\n",
    "`--mem-per-cpu=        # memory required for each CPU`<br />\n",
    "`--gres=               # \"general resource\" (i.e. GPUs)`<br />\n",
    "`--time=               # requested wall time`<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LUNCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff\n",
    "\n",
    "### What are Nodes?\n",
    "Nodes are essentially standalone computers with their own CPU cores, RAM, local storage, and maybe GPUs. \n",
    "<br>\n",
    "<img src=\"static/node-diagram.png\" alt=\"Node diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "HPC clusters (or just clusters) will consist of multiple nodes connected together through a (sometimes fast) network. <br>\n",
    "<img src=\"static/cluster-diagram.png\" alt=\"Cluster diagram\" width=\"400\">\n",
    "<img src=\"static/shared-storage-diagram.png\" alt=\"Shared storage diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "Nodes cannot collaborate on problems unless they are running a programmed designed that way.\n",
    "\n",
    "It's like clicking your mouse on your PC, and expecting the click to register on a colleague's PC. \n",
    "\n",
    "It's possible, but needs a special program/protocol to do so!\n",
    "\n",
    "Most programs in bioinformatics, health sciences, and statistics (that I know of) aren't setup to have multiple nodes cooperate. Notable exceptions are Tensorflow and Py-Torch, Relion, and Gromacs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "### So why are tasks useful/important?\n",
    "\n",
    "The Slurm task model was created with \"traditional HPC\" in mind\n",
    "* `srun` creates `ntasks` instances of a program which coordinate using MPI\n",
    "* Some applications are designed to use multiple cores per task (hybrid MPI-OpenMP) for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But this isn't a parallel programming workshop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tasks are not as relevant in bioinformatics, but Slurm nevertheless uses tasks for accounting/profiling purposes. \n",
    "\n",
    "Therefore, it's useful to have an understanding of tasks in order to interpret some of Slurm's job accounting/profiling outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "### What are tasks?\n",
    "Tasks are a collection of resources (CPU cores, GPUs) expected to perform the same \"task\", or used by a single program e.g., via threads, Python multiprocessing, or OpenMP.\n",
    "<img src=\"static/tasks-diagram1.png\" alt=\"Tasks diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "A task can only be given resources co-located on a node. <br>\n",
    "Multiple tasks requested by `sbatch` or `salloc` can be spread across multiple nodes (unless `--nodes=` is specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if we have two nodes with 4 CPU cores each:\n",
    "\n",
    "requesting 1 task and 8 cpus-per-task won't work.\n",
    "\n",
    "But requesting 2 tasks and 4 cpus-per-task will!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most data science, statistics, bionformatics, health-science work will use `--ntasks=1`, and using `--cpus-per-task`. \n",
    "\n",
    "If you see/hear anything to do with \"distributed\" or MPI (e.g. distributed ML), you may want to change these options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "### A review of launching jobs (`srun` vs `sbatch` and `salloc`)\n",
    "\n",
    "TL;DR:\n",
    "* `sbatch` requests resources for use with a script\n",
    "* `salloc` requests resources to be used interactively\n",
    "* `srun` runs programs/scripts using resources requested by `sbatch` and `salloc`\n",
    "    * When run \"inside\" a job, `srun` will use the resources requested in the parent request\n",
    "    * When run \"outside\" a job, `srun` will need to be passed the resource request e.g. `--ntasks`\n",
    "\n",
    "`srun` will execute `ntasks` instances of the same command/script/program. e.g.,\n",
    "\n",
    "`srun echo hello world` will run `echo` equal to the number of tasks requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue\n",
    "\n",
    "Slurm has lots of data on your jobs and the cluster!\n",
    "\n",
    "Primary utilities discussed in this section:\n",
    "* `squeue`    _Live_ Job queue data\n",
    "* `scontrol`  _Live_ Singular job data\n",
    "* `sinfo`     _Live_ Cluster data\n",
    "\n",
    "This section show you how to get more detailed information about:\n",
    "* the queue,\n",
    "* other jobs in the queue, and\n",
    "* the state/business of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "### Building on the basics: `squeue`\n",
    "\n",
    "`squeue` shows everyone's job in the queue (passing `-u <username>`) shows only `<username>`'s jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           8516030      gpuq interact bollands  R    1:30:11      1 gpu-p100-n01\n",
      "           8515707      gpuq cryospar cryospar  R    3:04:59      1 gpu-p100-n01\n",
      "           8511988 interacti sys/dash    yan.a  R   20:15:53      1 sml-n03\n",
      "           8516092 interacti     work jackson.  R    1:21:42      1 sml-n01\n"
     ]
    }
   ],
   "source": [
    "squeue | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "Getting a bit more: `squeue --long` makes things more legible adds the \"time_limit\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 03 12:57:40 2022\n",
      "             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n",
      "           8649808 gpuq_larg   AF2.2g iskander  RUNNING    4:34:07 5-00:00:00      1 gpu-a100-n02\n",
      "           8649805 gpuq_larg   AF2.2g iskander  RUNNING 1-03:47:14 5-00:00:00      1 gpu-a100-n01\n",
      "           8664606 interacti sys/dash     wu.y  RUNNING    2:12:59   8:00:00      1 med-n01\n"
     ]
    }
   ],
   "source": [
    "squeue --long | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "But what if we want _even more_ information?\n",
    "\n",
    "We have to make use of the formatting options!\n",
    "\n",
    "```\n",
    "$ squeue --Format field1,field2,...\n",
    "```\n",
    "\n",
    "OR use the environment variable `SQUEUE_FORMAT2`. Useful fields:\n",
    "\n",
    "| Resources related | Time related | Scheduling   |\n",
    "| :---              | :---         | :---         |\n",
    "| `NumCPUs`         | `starttime`  | `JobId`      |\n",
    "| `NumNodes`        | `submittime` | `name`       |\n",
    "| `minmemory`       | `pendingtime`| `partition`  |\n",
    "| `tres-alloc`      | `timelimit`  | `priority`   |\n",
    "| `minmemory`       | `timeleft`   | `reasonlist` |\n",
    "|                   | `timeused`   | `workdir`    |\n",
    "|                   |              | `state`      |\n",
    "\n",
    "You can always use `man squeue` to see the entire list of options.\n",
    "\n",
    "So you don't have to type out the fields, I recommend aliasing the the command with your fields of choice in `~/.bashrc` e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   NAME   PARTITION  ST TRES_ALLOC                                                  TIME_LIMIT  TIME_LEFT   \n",
      "8517002 R      bigmem     R  cpu=22,mem=88G,node=1,billing=720984                        1-00:00:00  23:35:18    \n",
      "8516030 intera gpuq       R  cpu=2,mem=20G,node=1,billing=44,gres/gpu=1,gres/gpu:p100=1  8:00:00     4:43:00     \n",
      "8515707 cryosp gpuq       R  cpu=8,mem=17G,node=1,billing=44,gres/gpu=1,gres/gpu:p100=1  2-00:00:00  1-19:08:12  \n",
      "8511988 sys/da interactiv R  cpu=8,mem=16G,node=1,billing=112                            1-00:00:00  1:57:18     \n"
     ]
    }
   ],
   "source": [
    "alias sqv=\"squeue --Format=jobid:8,name:6' ',partition:10' ',statecompact:3,tres-alloc:60,timelimit:12,timeleft:12\"\n",
    "sqv | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   NAME   PARTITION  ST TRES_ALLOC                                                  TIME_LIMIT  TIME_LEFT   \n",
      "8516851 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516850 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516849 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516848 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n"
     ]
    }
   ],
   "source": [
    "sqv -u bedo.j | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "### Getting detailed information of your running/pending job\n",
    "\n",
    "`scontrol show job <jobid>`\n",
    "\n",
    "Useful if you care only about a specific job.\n",
    "\n",
    "It's very useful when debugging jobs.\n",
    "\n",
    "A lot of information without needing lots of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=8516360 JobName=Extr16S23S\n",
      "   UserId=woodruff.c(2317) GroupId=allstaff(10908) MCS_label=N/A\n",
      "   Priority=324 Nice=0 Account=wehi QOS=normal\n",
      "   JobState=RUNNING Reason=None Dependency=(null)\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n",
      "   RunTime=00:21:53 TimeLimit=2-00:00:00 TimeMin=N/A\n",
      "   SubmitTime=2022-10-20T11:37:49 EligibleTime=2022-10-20T11:37:49\n",
      "   AccrueTime=2022-10-20T11:37:49\n",
      "   StartTime=2022-10-20T14:28:03 EndTime=2022-10-22T14:28:03 Deadline=N/A\n",
      "   PreemptEligibleTime=2022-10-20T14:28:03 PreemptTime=None\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-10-20T14:28:03 Scheduler=Main\n",
      "   Partition=regular AllocNode:Sid=vc7-shared:12938\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\n",
      "   NodeList=med-n24\n",
      "   BatchHost=med-n24\n",
      "   NumNodes=1 NumCPUs=32 NumTasks=32 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n",
      "   TRES=cpu=32,mem=48G,node=1,billing=128\n",
      "   Socks/Node=* NtasksPerN:B:S:C=32:0:*:* CoreSpec=*\n",
      "   MinCPUsNode=32 MinMemoryNode=48G MinTmpDiskNode=0\n",
      "   Features=(null) DelayBoot=00:00:00\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n",
      "   Command=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/ribosomal_16S23S_extract_singlespecies.sh Staphylococcus epidermidis 32\n",
      "   WorkDir=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell\n",
      "   StdErr=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/slurm-8516360.out\n",
      "   StdIn=/dev/null\n",
      "   StdOut=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/slurm-8516360.out\n",
      "   Power=\n",
      "   MailUser=woodruff.c@wehi.edu.au MailType=END,FAIL\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scontrol show job 8516360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your jobs and the Job Queue cont.\n",
    "### Monitoring the cluster\n",
    "\n",
    "Being able to understand the state of the cluster, can help understand why your job might be waiting.\n",
    "\n",
    "Or, you can use the information to your advantage to reduce wait times.\n",
    "\n",
    "To view the state of the cluster, we're going to use the `sinfo` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION        AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
      "interactive         up 1-00:00:00      4    mix med-n03,sml-n[01-03]\n",
      "interactive         up 1-00:00:00      1  alloc med-n02\n",
      "interactive         up 1-00:00:00      1   idle med-n01\n",
      "regular*            up 2-00:00:00     42    mix lrg-n[02-03],med-n[03-05,07-09,12-13,18,20-23,25-27,29-30],sml-n[02-20,22-24]\n",
      "regular*            up 2-00:00:00     13  alloc lrg-n04,med-n[02,06,10-11,14-17,19,24,28],sml-n21\n",
      "long                up 14-00:00:0     40    mix med-n[03-05,07-09,12-13,18,20-23,25-27,29-30],sml-n[02-20,22-24]\n",
      "long                up 14-00:00:0     12  alloc med-n[02,06,10-11,14-17,19,24,28],sml-n21\n",
      "bigmem              up 2-00:00:00      3    mix lrg-n02,med-n[03-04]\n",
      "bigmem              up 2-00:00:00      1  alloc med-n02\n",
      "bigmem              up 2-00:00:00      1   idle lrg-n01\n",
      "gpuq                up 2-00:00:00      1    mix gpu-p100-n01\n",
      "gpuq                up 2-00:00:00     11   idle gpu-a30-n[01-07],gpu-p100-n[02-05]\n",
      "gpuq_interactive    up   12:00:00      1    mix gpu-a10-n01\n",
      "gpuq_large          up 2-00:00:00      3   idle gpu-a100-n[01-03]\n"
     ]
    }
   ],
   "source": [
    "sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "Like `squeue`, we can augment `sinfo`'s behaviour with options.\n",
    "\n",
    "A very useful option is to use the `-N` (N for nodes) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELIST      NODES        PARTITION STATE \n",
      "gpu-a10-n01       1 gpuq_interactive mix   \n",
      "gpu-a30-n01       1             gpuq idle  \n",
      "gpu-a30-n02       1             gpuq idle  \n",
      "gpu-a30-n03       1             gpuq idle  \n"
     ]
    }
   ],
   "source": [
    "sinfo -N | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And now the data is now node-oriented instead of partition oriented!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "But just knowing whether nodes are \"idle\", \"mixed\", or \"allocated\" is not the _most useful_ information.\n",
    "\n",
    "We can add detail with formatting options as well.\n",
    "\n",
    "| CPU | memory | gres (GPU) | node state | time |\n",
    "| :---| :--- | :--- | :--- | :--- |\n",
    "| `CPUsState` | `FreeMem` | `GresUsed` | `StateCompact` | `Time` |\n",
    "| | `AllocMem` | `Gres` | | |\n",
    "| | `Memory` | | | |\n",
    "\n",
    "* CPUs occupied/available/total: CPUsState\n",
    "* memory occupied/available/total: FreeMem, AllocMem, Memory\n",
    "* gres (GPU) occupied/available: GresUsed, Gres\n",
    "* State of the node (e.g. whether the node is down): StateCompact\n",
    "* Max time: Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELIST    PARTITION  CPUS(A/I/O/T) FREE_MEM MEMORY   GRES_USED           GRES       STATE   TIMELIMIT           \n",
      "gpu-a10-n01 gpuq_inter 0/48/0/48     163914   257417   gpu:A10:0(IDX:N/A)  gpu:A10:4  idle    12:00:00            \n",
      "gpu-a30-n01 gpuq       0/96/0/96     450325   511362   gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n",
      "gpu-a30-n02 gpuq       0/96/0/96     436435   511362   gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n",
      "gpu-a30-n03 gpuq       0/96/0/96     497816   511362   gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n"
     ]
    }
   ],
   "source": [
    "sinfo -NO nodelist:11' ',partition:10' ',cpusstate:13' ',freemem:8' ',memory:8' ',gresused,gres:11,statecompact:8,time | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "For newer Slurm versions, the GUI tool `sview` is an option.\n",
    "\n",
    "It's functionality is currently a little limited and not customizable.\n",
    "\n",
    "Requires and X11 server running on your computer (Windows: MobaXTerm, Mac: XQuartz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(sview:4266): Gtk-\u001b[1;33mWARNING\u001b[0m **: \u001b[34m16:00:18.949\u001b[0m: cannot open display: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling\n",
    "\n",
    "This section will look at using command-line tools to obtain visibility into how your job is performing.\n",
    "\n",
    "| type of data | Live | Historical |\n",
    "| --- | --- | --- |\n",
    "| <strong>good for</strong> | debugging | debugging |\n",
    "| | evaluating utilization | profiling |\n",
    "| <strong>drawbacks</strong> | uses system tools, so requires some system understanding | Only provides data when jobs are completed |\n",
    "\n",
    "We will look at:\n",
    "* `htop` for _Live_ Process activity on nodes\n",
    "* `nvidia-smi` for _Live_ GPU activity on nodes\n",
    "* `seff` for _Historical_ job CPU and memory usage data\n",
    "* `dcgmstats` for _Historical_ job GPU usage data\n",
    "* `sacct` for _Historical_ job data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "### Live monitoring of jobs\n",
    "A limitation of Slurm is that it doesn't offer tools that provide up-to-date data of a job as it is running. \n",
    "\n",
    "Instead, to obtain insight into current activity of a job, we can use general system tools.\n",
    "\n",
    "The main obstacle with using these tools is that they do not use job IDs - you must match jobs with _processes_ on a node.\n",
    "\n",
    "To do this, you use `squeue` to find which node(s) your job(s) are running on.<br>\n",
    "Then, you will use the `ssh` command to move to that node and monitor the system's activity.\n",
    "\n",
    "Another \"drawback\" is that some of the data may require a bit of operating system understanding to interpret.\n",
    "\n",
    "But nevertheless, the tools are robust and useful in helping us understand how our jobs are performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "#### Live monitoring: CPU, memory, IO activity\n",
    "`htop` is a utility often installed on HPC clusters for monitoring processes.\n",
    "\n",
    "It can be used to look at the CPU, memory, and IO utilization of a running process. \n",
    "\n",
    "It's not a Slurm tool, but is nevertheless very useful in monitoring jobs' activity and diagnosing issues.\n",
    "\n",
    "To show only your processes, execute `htop -u $USER`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "\n",
    "`htop` shows the individual CPU core utilization on the top, followed by memory utilization and some misc. information.\n",
    "\n",
    "The bottom panel shows the process information\n",
    "\n",
    "Relevant Headings:\n",
    "* USER: User that owns the process\n",
    "* PID: Process ID\n",
    "* %CPU: % of a single core that a process is using e.g. 400% means process is using 4 cores\n",
    "* %MEM: % of node's total RAM that process is using\n",
    "* VSZ: \"Virtual\" memory (bytes) - the memory a process \"thinks\" it's using\n",
    "* RSS: \"Resident\" memory (bytes) - the actual physical memory a process is using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "You can organize the process information into \"trees\" by pressing `F5`\n",
    "\n",
    "You can add IO information by\n",
    "1. Press `F2` (Setup)\n",
    "2. Press down three times to move the cursor to \"Columns\" and press right twice\n",
    "3. The cursor should now be in \"Available Columns\". Scroll down to `IO_READ_RATE` and press enter\n",
    "4. Scroll down to `IO_WRITE_RATE` and press enter\n",
    "5. Press `F10` to exit. \n",
    "You should now be able to see read/write rates for processes that you have permissions for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<strong>Tips</strong>: \n",
    "* `htop` configurations are saved in `~/.config/htop`. Delete this folder to reset your `htop` conifguration.\n",
    "* `ps` and `pidstat` are useful alternatives which can be incorporated into scripts.\n",
    "* Some systems may not have `htop` installed, in which case `top` can be used instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "\n",
    "#### Live monitoring: GPU activity\n",
    "\n",
    "To monitor activity of Milton's NVIDIA GPUs, we must rely on NVIDIA's `nvidia-smi` tool.\n",
    "\n",
    "`nvidia-smi` shows information about the memory and compute utilization, process allocation and other details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Like `htop`, `nvidia-smi` only provides information on processes running on a GPU. If your job is occupying an entire node and all its GPUs, it should be straightforward to determine which GPUs you've been allocated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But if your job is sharing a node with other jobs, you might not know straight away which GPU your job has been allocated. You can determine this by\n",
    "* inferring by the command being run on a GPU, or\n",
    "* using `squeue` with extra formatting options as discussed previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<strong>Note</strong>:\n",
    "This tool is available only on GPU nodes where the CUDA drivers are installed, so you must `ssh` to a `gpu` node to try it.\n",
    "\n",
    "<strong>Tip</strong>: Combine `nvidia-smi` with `watch` to automatically update the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "### Historical monitoring of jobs\n",
    "Slurm tools and plugins are generally easier to use because they provide information on a per-job basis, meaning there's no need to match processes with jobs like previously discussed.\n",
    "\n",
    "<strong>Tip</strong>: _generally_, results are more reliable when executing commands with `srun`.\n",
    "\n",
    "<strong>NOTE</strong>: `seff` results are most accurate when executing commands with `srun`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "#### Historical data: CPU and memory utilization\n",
    "The `seff` command shows the memory and CPU utilization of a job that has <strong>ended</strong>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 8665813\n",
      "Cluster: milton\n",
      "User/Group: yang.e/allstaff\n",
      "State: COMPLETED (exit code 0)\n",
      "Nodes: 1\n",
      "Cores per node: 4\n",
      "CPU Utilized: 00:09:04\n",
      "CPU Efficiency: 99.27% of 00:09:08 core-walltime\n",
      "Job Wall-clock time: 00:02:17\n",
      "Memory Utilized: 1.95 GB (estimated maximum)\n",
      "Memory Efficiency: 48.83% of 4.00 GB (1.00 GB/core)\n"
     ]
    }
   ],
   "source": [
    "seff 8665813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "`sacct` is a general job history querying command-line tool that can provide lots of information about your _past_ jobs.\n",
    "\n",
    "<strong>Note</strong>: `sacct` data can take a few minutes to be updated, so is best for jobs that have just finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following `sacct` command shows your job data for jobs since 1st Nov:\n",
    "* Job steps' ID and name\n",
    "* Requested resources\n",
    "* Elapsed time\n",
    "* The quantity of data written and read\n",
    "* The quantity of virtual and resident memory used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the IO and memory values shown will be for the highest use <strong>task</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         JobID    JobName NCPUS        NodeList    Elapsed      State  MaxDiskRead MaxDiskWrite  MaxVMSize     MaxRSS \n",
      "-------------- ---------- ----- --------------- ---------- ---------- ------------ ------------ ---------- ---------- \n",
      "       8664599 sys/dashb+     2         sml-n01 1-00:00:22    TIMEOUT                                                 \n",
      " 8664599.batch      batch     2         sml-n01 1-00:00:23  CANCELLED      102.64M       15.11M   1760920K     99812K \n",
      "8664599.extern     extern     2         sml-n01 1-00:00:22  COMPLETED        0.00M            0    146612K        68K \n"
     ]
    }
   ],
   "source": [
    "sacct -S 2022-11-01 -o jobid%14' ',jobname,ncpus%5' ',nodelist,elapsed,state,maxdiskread,maxdiskwrite,maxvmsize,maxrss | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "#### Historical data: GPU activity\n",
    "By default, Slurm doesn't have the ability to produce stats on GPU usage.\n",
    "\n",
    "WEHI's ITS have implemented the `dcgmstats` NVIDIA Slurm plugin which can produce these summary stats.\n",
    "\n",
    "To use this plugin, pass the `--comment=dcgmstats` option to `srun`, `salloc`, or `sbatch`.\n",
    "\n",
    "If your job requested at least one GPU, an extra output file will be generated in the working directory called `dcgm-stats-<jobid>.out`. The output file will contain a table for each GPU requested by the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling cont.\n",
    "### Summary\n",
    "* live monitoring:\n",
    "    * `htop` for CPU, memory, and IO data (requires configuration)\n",
    "    * `nvidia-smi` for GPU activity\n",
    "    * both require matching jobs to hardware and running processes\n",
    "* historical monitoring:\n",
    "    * `seff` command for simple CPU and memory utilization data for one job\n",
    "    * `sacct` command for memory and IO data for multiple past jobs\n",
    "    * `dcgmstats` Slurm plugin for GPU stats for a single Slurm job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sbatch Scripting Features\n",
    "Sbatch scripts have a lot of nice features that extend beyond requesting resources. This section will look at some of these useful features which you can use in your workflows.\n",
    "\n",
    "This section will look at:\n",
    "* getting email notifications\n",
    "* changing `stdout` and `stderr` files\n",
    "* controlling how jobs depend on each other\n",
    "* making use of job environments and interpreters (e.g. python or R)\n",
    "* submitting `sbatch` scripts without a script\n",
    "\n",
    "We're going to start with a simple R script submitted by wrapper sbatch script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```r\n",
    "## matmul.rscript\n",
    "# multiplies two matrices together and prints how long it takes.\n",
    "\n",
    "print(\"starting the matmul R script!\")\n",
    "nrows = 1e3\n",
    "print(paste0(\"elem: \", nrows, \"*\", nrows, \" = \", nrows*nrows))\n",
    "\n",
    "# generating matrices\n",
    "M <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "N <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "\n",
    "# start matmul\n",
    "start.time <- Sys.time()\n",
    "invisible(M %*% N)\n",
    "end.time <- Sys.time()\n",
    "\n",
    "# Getting final time and writing to stdout\n",
    "elapsed.time <- difftime(time1=end.time, time2=start.time, units=\"secs\")\n",
    "print(elapsed.time)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"starting the matmul R script!\"\n",
      "[1] \"elem: 1000*1000 = 1e+06\"\n",
      "Time difference of 0.06260109 secs\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev0\n",
    "\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "### Email notifications\n",
    "Getting notifications about the status of your Slurm jobs remove the need to `ssh` onto Milton and running `squeue` to get the status of your jobs.\n",
    "\n",
    "Instead, it will notify you when your job state has changed e.g. when it has started or ended.\n",
    "\n",
    "To enable this behaviour, add the following options to your job scripts:\n",
    "```\n",
    "--mail-user=me@gmail.com\n",
    "--mail-type=ALL\n",
    "```\n",
    "This sends emails to `me@gmail.com` when the job state changes. \n",
    "\n",
    "If you only want to know when your job goes through certain states, e.g. if it fails or is pre-empted but not when it starts or finishes:\n",
    "* BEGIN: job starts\n",
    "* END: job finishes successfully\n",
    "* FAIL: job fails\n",
    "* TIME_LIMIT: job reaches time limit\n",
    "* TIME_LIMIT_50/80/90: job reaches 50%/80%/90% of time limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"starting the matmul R script!\"\n",
      "[1] \"elem: 1000*1000 = 1e+06\"\n",
      "Time difference of 0.06343555 secs\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev1 - email notifications\n",
    "\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mail-user=yang.e@wehi.edu.au\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "\n",
    "### a short aside on `stdout` and `stderr`\n",
    "Linux uses has two main \"channels\" to send output messages to. One is \"stdout\" (standard out), and the other is \"stderr\" (standard error).\n",
    "\n",
    "If you have ever used the `|` `>` or `>>` shell scripting features, then you've _redirected_ `stdout` somewhere else e.g., to another command, a file, or the void (`/dev/null`).\n",
    "\n",
    "```bash\n",
    "$ ls dir-that-doesnt-exist\n",
    "ls: cannot access dir-that-doesnt-exist: No such file or directory # this is a stderr output`\n",
    "```\n",
    "\n",
    "```bash\n",
    "$ ls ~\n",
    "bin cache Desktop Downloads ... # this is a stdout output!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "### Redirecting job's `stderr` and `stdout`\n",
    "By default:\n",
    "* job's working directory is the directory you submitted from\n",
    "* `stdout` is directed to `slurm-<jobid>.out` in the job's working directory\n",
    "* `stderr` is directed to wherever `stdout` is directed to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Redirect `stderr` and `stdout` with `--error` and `--output` options. They work with both relative and absolute paths, e.g.\n",
    "```\n",
    "--error=/dev/null\n",
    "--output=path/to/output.out\n",
    "```\n",
    "where paths are resolved relative to the job's working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Variables can be used, like:\n",
    "* `%j`: job ID\n",
    "* `%x`: job name\n",
    "* `%u`: username\n",
    "* `%t`: task ID i.e., seperate file per task\n",
    "* `%N`: node name i.e., seperate file per nodes in job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"starting the matmul R script!\"\n",
      "[1] \"elem: 1000*1000 = 1e+06\"\n",
      "Time difference of 0.06532145 secs\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev2 - added --output and --error options\n",
    "\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mail-user=yang.e@wehi.edu.au\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --output=logs/matmul-%j.out\n",
    "#SBATCH --error=logs-debug/matmul-%j.err\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "### Using job dependancies\n",
    "Slurm allows for submitted jobs to wait for another job to start or finish before beginning. While probably not as effective as workflow managers like Nextflow, Slurm's job dependencies can still be useful for simple workflows.\n",
    "\n",
    "Make a job dependant on another by passing the `--dependency` option with one of the following values:\n",
    "* `afterok:jobid1:jobid2...` waits for `jobid1`, `jobid2` ... to complete successfully\n",
    "* `afterany:jobid1:jobid2...` \"                              \" to finish (fail, complete, cancelled)\n",
    "* `after:jobid1:jobid2...` \"                                 \" to start or are cancelled.\n",
    "\n",
    "e.g. `--dependency=afterok:12345678` will make the job wait for job `12345678` to complete successfully before starting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "### Making use of job environments and interpreters\n",
    "By default, when you submit a Slurm job, Slurm copies all the environment variables in your environment and adds some extra for the job to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "export VAR1=\"here is some text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "echo $VAR1\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/env-vars1.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8681656\n"
     ]
    }
   ],
   "source": [
    "sbatch demo-scripts/env-vars1.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is some text\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8681656.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<strong>Note</strong>: For reproducibility reasons, a Slurm script that relies on environment variables can be submitted inside a wrapper script which first exports the relevant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "Alternatively, you can use the `--export` option which allows you to set specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is some text\n"
     ]
    }
   ],
   "source": [
    "echo $VAR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8681761\n"
     ]
    }
   ],
   "source": [
    "sbatch --export=VAR1=\"this is some different text\" demo-scripts/env-vars1.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is some different text\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8681761.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This feature is especially useful when submitting jobs inside wrapper scripts.\n",
    "\n",
    "You can also use the `--export-file` option to specify a file with a list of `export VAR=value` pairs that you wish the script to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "Slurm also adds environment variables that enable job parameters use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=2\n",
      "\n",
      "echo I am running on ${SLURM_NODELIST}\n",
      "echo with ${SLURM_NTASKS} tasks\n",
      "echo and ${SLURM_CPUS_PER_TASK} CPUs per task\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/env-vars2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8681710\n"
     ]
    }
   ],
   "source": [
    "sbatch demo-scripts/env-vars2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am running on sml-n03\n",
      "with 1 tasks\n",
      "and 2 CPUs per task\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8681710.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These Slurm environment variables make it easy to supply parallelisation parameters to a program e.g. specifying number of threads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "### Submitting scripts with different interpreters\n",
    "Typically scripts submitted by `sbatch` use the `bash` or `sh` interpreter (e.g. `#!/bin/bash`), but it may be more convenient to use a different interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can do this by changing the \"hash bang\" statement at the top of the script. To demonstrate this, we can take our original R matmul script, and add a \"hash bang\" statement to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "## matmul.rscript\n",
      "\n",
      "print(\"starting the matmul R script!\")\n",
      "nrows = 1e3\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/matmul-interpreter1.rscript | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The statement in the above looks for the Rscript in your current environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively, you can specify the absolute path to the interpreter.\n",
    "\n",
    "e.g. `#!/stornext/System/data/apps/R/openBLAS/R-4.2.1/lib64/R/bin/Rscript`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "Changing the interpreter still allows you to access the extra Slurm environment variables, but in a way appropriate to the interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=2\n",
      "#SBATCH --mem=4G\n",
      "\n",
      "## matmul.rscript\n",
      "\n",
      "print(\"starting the matmul R script!\")\n",
      "paste(\"using\", Sys.getenv(\"SLURM_NTASKS\"), \"tasks\")\n",
      "paste(\"and\", Sys.getenv(\"SLURM_CPUS_PER_TASK\"), \"CPUs per task\")\n",
      "nrows = 1e3\n",
      "print(paste0(\"elem: \", nrows, \"*\", nrows, \" = \", nrows*nrows))\n",
      "\n",
      "# generating matrices\n",
      "M <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
      "N <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
      "\n",
      "# start matmul\n",
      "start.time <- Sys.time()\n",
      "invisible(M %*% N)\n",
      "end.time <- Sys.time()\n",
      "\n",
      "# Getting final time and writing to stdout\n",
      "elapsed.time <- difftime(time1=end.time, time2=start.time, units=\"secs\")\n",
      "print(elapsed.time)\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/matmul-interpreter2.rscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8682077\n"
     ]
    }
   ],
   "source": [
    "sbatch demo-scripts/matmul-interpreter2.rscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"starting the matmul R script!\"\n",
      "[1] \"using 1 tasks\"\n",
      "[1] \"and 2 CPUs per task\"\n",
      "[1] \"elem: 1000*1000 = 1e+06\"\n",
      "Time difference of 0.06340098 secs\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8682077.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`python` works similarly. Replace `Rscript` in the hash bang statement to `python`."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
