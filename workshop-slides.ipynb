{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intermediate Slurm on Milton\n",
    "### Delivered by WEHI Research Computing Platform\n",
    "\n",
    "<pre>Edward Yang    Michael Milton    Julie Iskander</pre><br>\n",
    "\n",
    "<img src=\"static/1200px-Slurm_logo.svg.png\" alt=\"Slurm\" width=\"100\"/>\n",
    "<img src=\"static/milton.png\" alt=\"Milton Mascot\" width=\"100\"/>\n",
    "<img src=\"static/WEHI_RGB_logo.png\" alt=\"WEHI logo\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [OPTIONAL SLIDE] Self Introductions!\n",
    "\n",
    "### Me\n",
    "* Civil Engineer by training\n",
    "* HPC by interest\n",
    "* Mostly code in Fortran, occasionally Python\n",
    "* I use HPC to simulate fluid and granular flows\n",
    "\n",
    "## How about you?\n",
    "* name\n",
    "* How you use Milton's HPC\n",
    "* Your coffee/tea order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background\n",
    "* We already ran an \"intro to Slurm\" workshop (recording on RCP website)\n",
    "* More \"advanced\" features of Slurm were highly requested\n",
    "* Both ITS and researchers would benefit\n",
    "    * ITS will have fewer issues to address\n",
    "    * researchers can accelerate their research <- High Priority for everyone!\n",
    "\n",
    "### Target Audience\n",
    "* You've submitted quite a few jobs via `sbatch`\n",
    "* You're familiar with resource requests. Like:\n",
    "    * using `--ntasks` and `--cpus-per-task`\n",
    "    * using `--mem` and/or `--memory-per-cpu`\n",
    "* You're wondering whether your jobs are utilizing resources efficiently\n",
    "* You're wondering how to make your life easier when using `sbatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Background cont.\n",
    "\n",
    "My goal for the session is to teach you how to:\n",
    "* get the status of the cluster\n",
    "* get information about your jobs\n",
    "* make use of `sbatch` scripting features\n",
    "* Run emabarrasingly parallel tasks\n",
    "* **bonus topic** submitting jobs from R or submitting `python` or `R` scripts without a wrapper script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda for Today\n",
    "\n",
    "12:00 - 12:30&emsp;<span style=\"color:blue\">Introduction & Housekeeping</span>\n",
    "\n",
    "12:30 - 13:00&emsp;Lunch\n",
    "\n",
    "13:00 - 13:30&emsp;Laying the groundwork: nodes, tasks and other Slurm terminology\n",
    "\n",
    "13:30 - 14:00&emsp;Understanding your jobs and the job queue\n",
    "\n",
    "13:30 - 14:00&emsp;Basic profiling of your jobs\n",
    "\n",
    "14:00 - 14:30&emsp;Slurm scripting features\n",
    "\n",
    "14:30 - 15:00&emsp;Embarrarsingly parallel examples\n",
    "\n",
    "15:00 - 15:30&emsp;R batchtools\n",
    "\n",
    "15:30 - 16:00&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction and Housekeeping\n",
    "\n",
    "### Format\n",
    "Slides + live coding\n",
    "\n",
    "Live coding will be on Milton, so make sure you're connected to WEHI's VPN or staff network, or use RAP:<br />\n",
    "rap.wehi.edu.au\n",
    "\n",
    "Please follow along to reinforce learning!\n",
    "\n",
    "Questions:\n",
    "* Put your hand up whenever you have a question or have an issue running things\n",
    "* Questions in the chat are welcome and will be addressed by helpers\n",
    "\n",
    "Material is available here:\n",
    "/link\n",
    "\n",
    "Feel free to download the notebook and follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction and Housekeeping Cont.\n",
    "### Expected understanding of\n",
    "* <span style=\"font-size:1.2em;\">Concept of \"resources\"</span><br />\n",
    "`CPUs`<br />\n",
    "`RAM/memory`<br />\n",
    "`Nodes`<br /><br />\n",
    "* <span style=\"font-size:1.2em;\">Job submission commands</span><br />\n",
    "`srun    # executes a command/script/binary across tasks`<br />\n",
    "`salloc  # allocates resources to be used (interactively and/or via srun)`<br />\n",
    "`sbatch  # submits a script for later execution on requested resources`<br /><br />\n",
    "* <span style=\"font-size:1.2em;\">resource request options</span><br />\n",
    "`--ntasks=             # \"tasks\" recognised by srun`<br />\n",
    "`--nodes=              # no. of nodes`<br />\n",
    "`--ntasks-per-node=    # tasks per node`<br />\n",
    "`--cpus-per-task=      # cpus per task`<br />\n",
    "`--mem=                # memory required for entire job`<br />\n",
    "`--mem-per-cpu=        # memory required for each CPU`<br />\n",
    "`--gres=               # \"general resource\" (i.e. GPUs)`<br />\n",
    "`--time=               # requested wall time`<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LUNCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff\n",
    "\n",
    "### What are Nodes?\n",
    "Nodes are essentially standalone computers with their own CPU cores, RAM, local storage, and maybe GPUs. \n",
    "<br>\n",
    "<img src=\"static/node-diagram.png\" alt=\"Node diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "HPC clusters (or just clusters) will consist of multiple nodes connected together through a (sometimes fast) network. <br>\n",
    "<img src=\"static/cluster-diagram.png\" alt=\"Cluster diagram\" width=\"400\">\n",
    "<img src=\"static/shared-storage-diagram.png\" alt=\"Shared storage diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "Nodes cannot collaborate on problems unless they are running a programmed designed that way.\n",
    "\n",
    "It's like clicking your mouse on your PC, and expecting the click to register on a colleague's PC. \n",
    "\n",
    "It's possible, but needs a special program/protocol to do so!\n",
    "\n",
    "Most programs in bioinformatics, health sciences, and statistics (that I know of) aren't setup to have multiple nodes cooperate. Notable exceptions are Tensorflow and Py-Torch, Relion, and Gromacs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff cont.\n",
    "\n",
    "### What are tasks?\n",
    "Tasks are a collection of resources (CPU cores, GPUs) expected to perform the same \"task\", or used by a single program e.g., via threads, Python multiprocessing, or OpenMP.\n",
    "\n",
    "<img src=\"static/tasks-diagram1.png\" alt=\"Tasks diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A task can only be given resources co-located on a node. Multiple tasks requested by `sbatch` or `salloc` can be spread across multiple nodes (unless `--nodes=` is specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`srun` will use the number of tasks requested by `salloc` or `sbatch` to run `ntasks` instances of the same command/script/program. e.g.,\n",
    "\n",
    "`srun echo hello world` will run `echo` equal to the number of tasks requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This was designed with \"traditional\" HPC in mind, where multiple instances of the same program would be created, and these instanced could cooperate (thanks to MPI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### why `ntasks` and  `cpus-per-task` then?\n",
    "This is because some \"traditional\" HPC would use multiprocessing (usually through OpenMP) where each program instance could utilize multiple cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most data science, statistics, bionformatics, health-science work will use `--ntasks=1`, and using `--cpus-per-task` . If you see/hear anything to do with \"distributed\" or MPI (e.g. distributed ML), you may want to change that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue\n",
    "\n",
    "_knowledge is power_\n",
    "\n",
    "### Building on the basics: `squeue`\n",
    "\n",
    "`squeue` shows everyone's job in the queue (passing `-u <username>`) shows only `<username>`'s jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           8516030      gpuq interact bollands  R    1:30:11      1 gpu-p100-n01\n",
      "           8515707      gpuq cryospar cryospar  R    3:04:59      1 gpu-p100-n01\n",
      "           8511988 interacti sys/dash    yan.a  R   20:15:53      1 sml-n03\n",
      "           8516092 interacti     work jackson.  R    1:21:42      1 sml-n01\n"
     ]
    }
   ],
   "source": [
    "squeue | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Getting a bit more: `squeue --long` makes things more legible adds the \"time_limit\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 20 12:07:43 2022\n",
      "             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n",
      "           8516030      gpuq interact bollands  RUNNING    1:30:13   8:00:00      1 gpu-p100-n01\n",
      "           8515707      gpuq cryospar cryospar  RUNNING    3:05:01 2-00:00:00      1 gpu-p100-n01\n",
      "           8511988 interacti sys/dash    yan.a  RUNNING   20:15:55 1-00:00:00      1 sml-n03\n"
     ]
    }
   ],
   "source": [
    "squeue --long | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "But what if we want _even more_ information?\n",
    "\n",
    "We have to make use of the formatting options!\n",
    "\n",
    "```\n",
    "$ squeue --Format field1,field2,...\n",
    "```\n",
    "\n",
    "OR use the environment variable `SQUEUE_FORMAT2`. Useful fields:\n",
    "\n",
    "| Resources related | Time related | Scheduling   |\n",
    "| :---              | :---         | :---         |\n",
    "| `NumCPUs`         | `starttime`  | `JobId`      |\n",
    "| `NumNodes`        | `submittime` | `name`       |\n",
    "| `minmemory`       | `pendingtime`| `partition`  |\n",
    "| `tres-alloc`      | `timelimit`  | `priority`   |\n",
    "| `minmemory`       | `timeleft`   | `reasonlist` |\n",
    "|                   | `timeused`   | `workdir`    |\n",
    "|                   |              | `state`      |\n",
    "\n",
    "You can always use `man squeue` to see the entire list of options.\n",
    "\n",
    "So you don't have to type out the fields, I recommend aliasing the the command with your fields of choice in `~/.bashrc` e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   NAME   PARTITION  ST TRES_ALLOC                                                  TIME_LIMIT  TIME_LEFT   \n",
      "8517002 R      bigmem     R  cpu=22,mem=88G,node=1,billing=720984                        1-00:00:00  23:35:18    \n",
      "8516030 intera gpuq       R  cpu=2,mem=20G,node=1,billing=44,gres/gpu=1,gres/gpu:p100=1  8:00:00     4:43:00     \n",
      "8515707 cryosp gpuq       R  cpu=8,mem=17G,node=1,billing=44,gres/gpu=1,gres/gpu:p100=1  2-00:00:00  1-19:08:12  \n",
      "8511988 sys/da interactiv R  cpu=8,mem=16G,node=1,billing=112                            1-00:00:00  1:57:18     \n"
     ]
    }
   ],
   "source": [
    "alias sqv=\"squeue --Format=jobid:8,name:6' ',partition:10' ',statecompact:3,tres-alloc:60,timelimit:12,timeleft:12\"\n",
    "sqv | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   NAME   PARTITION  ST TRES_ALLOC                                                  TIME_LIMIT  TIME_LEFT   \n",
      "8516851 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516850 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516849 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516848 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n"
     ]
    }
   ],
   "source": [
    "sqv -u bedo.j | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "### Getting detailed information of your running/pending job\n",
    "\n",
    "`scontrol show job <jobid>`\n",
    "\n",
    "Useful if you care only about a specific job.\n",
    "\n",
    "It's very useful when debugging jobs.\n",
    "\n",
    "A lot of information without needing lots of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=8516360 JobName=Extr16S23S\n",
      "   UserId=woodruff.c(2317) GroupId=allstaff(10908) MCS_label=N/A\n",
      "   Priority=324 Nice=0 Account=wehi QOS=normal\n",
      "   JobState=RUNNING Reason=None Dependency=(null)\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n",
      "   RunTime=00:21:53 TimeLimit=2-00:00:00 TimeMin=N/A\n",
      "   SubmitTime=2022-10-20T11:37:49 EligibleTime=2022-10-20T11:37:49\n",
      "   AccrueTime=2022-10-20T11:37:49\n",
      "   StartTime=2022-10-20T14:28:03 EndTime=2022-10-22T14:28:03 Deadline=N/A\n",
      "   PreemptEligibleTime=2022-10-20T14:28:03 PreemptTime=None\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-10-20T14:28:03 Scheduler=Main\n",
      "   Partition=regular AllocNode:Sid=vc7-shared:12938\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\n",
      "   NodeList=med-n24\n",
      "   BatchHost=med-n24\n",
      "   NumNodes=1 NumCPUs=32 NumTasks=32 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n",
      "   TRES=cpu=32,mem=48G,node=1,billing=128\n",
      "   Socks/Node=* NtasksPerN:B:S:C=32:0:*:* CoreSpec=*\n",
      "   MinCPUsNode=32 MinMemoryNode=48G MinTmpDiskNode=0\n",
      "   Features=(null) DelayBoot=00:00:00\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n",
      "   Command=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/ribosomal_16S23S_extract_singlespecies.sh Staphylococcus epidermidis 32\n",
      "   WorkDir=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell\n",
      "   StdErr=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/slurm-8516360.out\n",
      "   StdIn=/dev/null\n",
      "   StdOut=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/slurm-8516360.out\n",
      "   Power=\n",
      "   MailUser=woodruff.c@wehi.edu.au MailType=END,FAIL\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scontrol show job 8516360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your jobs and the Job Queue cont.\n",
    "### Monitoring the cluster\n",
    "\n",
    "Being able to understand the state of the cluster, can help understand why your job might be waiting.\n",
    "\n",
    "Or, you can use the information to your advantage to reduce wait times.\n",
    "\n",
    "To view the state of the cluster, we're going to use the `sinfo` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION        AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
      "interactive         up 1-00:00:00      4    mix med-n03,sml-n[01-03]\n",
      "interactive         up 1-00:00:00      1  alloc med-n02\n",
      "interactive         up 1-00:00:00      1   idle med-n01\n",
      "regular*            up 2-00:00:00     42    mix lrg-n[02-03],med-n[03-05,07-09,12-13,18,20-23,25-27,29-30],sml-n[02-20,22-24]\n",
      "regular*            up 2-00:00:00     13  alloc lrg-n04,med-n[02,06,10-11,14-17,19,24,28],sml-n21\n",
      "long                up 14-00:00:0     40    mix med-n[03-05,07-09,12-13,18,20-23,25-27,29-30],sml-n[02-20,22-24]\n",
      "long                up 14-00:00:0     12  alloc med-n[02,06,10-11,14-17,19,24,28],sml-n21\n",
      "bigmem              up 2-00:00:00      3    mix lrg-n02,med-n[03-04]\n",
      "bigmem              up 2-00:00:00      1  alloc med-n02\n",
      "bigmem              up 2-00:00:00      1   idle lrg-n01\n",
      "gpuq                up 2-00:00:00      1    mix gpu-p100-n01\n",
      "gpuq                up 2-00:00:00     11   idle gpu-a30-n[01-07],gpu-p100-n[02-05]\n",
      "gpuq_interactive    up   12:00:00      1    mix gpu-a10-n01\n",
      "gpuq_large          up 2-00:00:00      3   idle gpu-a100-n[01-03]\n"
     ]
    }
   ],
   "source": [
    "sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "Like `squeue`, we can augment `sinfo`'s behaviour with options.\n",
    "\n",
    "A very useful option is to use the `-N` (N for nodes) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELIST      NODES        PARTITION STATE \n",
      "gpu-a10-n01       1 gpuq_interactive mix   \n",
      "gpu-a30-n01       1             gpuq idle  \n",
      "gpu-a30-n02       1             gpuq idle  \n",
      "gpu-a30-n03       1             gpuq idle  \n"
     ]
    }
   ],
   "source": [
    "sinfo -N | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And now the data is now node-oriented instead of partition oriented!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "But just knowing whether nodes are \"idle\", \"mixed\", or \"allocated\" is not the _most useful_ information.\n",
    "\n",
    "We can add detail with formatting options as well.\n",
    "\n",
    "| CPU | memory | gres (GPU) | node state | time |\n",
    "| :---| :--- | :--- | :--- | :--- |\n",
    "| `CPUsState` | `FreeMem` | `GresUsed` | `StateCompact` | `Time` |\n",
    "| | `AllocMem` | `Gres` | | |\n",
    "| | `Memory` | | | |\n",
    "\n",
    "* CPUs occupied/available/total: CPUsState\n",
    "* memory occupied/available/total: FreeMem, AllocMem, Memory\n",
    "* gres (GPU) occupied/available: GresUsed, Gres\n",
    "* State of the node (e.g. whether the node is down): StateCompact\n",
    "* Max time: Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELIST     PARTITION    CPUS(A/I/O/T)FREE_MEMMEMORY  GRES_USED           GRES       STATE   TIMELIMIT           \n",
      "gpu-a10-n01  gpuq_interact2/46/0/48    71517   257417  gpu:A10:1(IDX:0)    gpu:A10:4  mix     12:00:00            \n",
      "gpu-a30-n01  gpuq         0/96/0/96    462381  511362  gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n",
      "gpu-a30-n02  gpuq         0/96/0/96    401605  511362  gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n",
      "gpu-a30-n03  gpuq         0/96/0/96    362552  511362  gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n"
     ]
    }
   ],
   "source": [
    "sinfo -NO nodelist:13,partition:13,cpusstate:13,freemem:8,memory:8,gresused,gres:11,statecompact:8,time | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue cont.\n",
    "\n",
    "For newer Slurm versions, the GUI tool `sview` is an option\n",
    "\n",
    "It's functionality is currently a little less limited and not customizable, but also an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(sview:4266): Gtk-\u001b[1;33mWARNING\u001b[0m **: \u001b[34m16:00:18.949\u001b[0m: cannot open display: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Profiling of Your Jobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: sacct: command not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sacct -S -E -o jobid,jobname,alloctres,elapsed,end,start,exitcode,ncpus,nodelist,nnodes,submit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: sinfo: command not found\n",
      "bash: syntax error near unexpected token `newline'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sinfo -NO nodehost,partition,statecompact,available,cpusstate,allocmem,memory,gres,gresused\n",
    "scontrol show job <job id>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Job Profiling\n",
    "\n",
    "ssh node\n",
    "\n",
    "nvidia-smi\n",
    "\n",
    "htop (and useful features)\n",
    "\n",
    "seff\n",
    "\n",
    "dcgmstats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sbatch Scripting Features\n",
    "\n",
    "We're going to start with a simple R script submitted by wrapper sbatch script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```r\n",
    "## matmul.rscript\n",
    "\n",
    "print(\"starting the matmul R script!\")\n",
    "nrows = 1e3\n",
    "print(paste0(\"elem: \", nrows, \"*\", nrows, \" = \", nrows*nrows))\n",
    "\n",
    "# generating matrices\n",
    "M <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "N <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "\n",
    "# start matmul\n",
    "start.time <- Sys.time()\n",
    "invisible(M %*% N)\n",
    "end.time <- Sys.time()\n",
    "\n",
    "# Getting final time and writing to stdout\n",
    "elapsed.time <- difftime(time1=end.time, time2=start.time, units=\"secs\")\n",
    "print(elapsed.time)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: module: command not found\n",
      "Fatal error: cannot open file 'matmul.rscript': No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev0\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "\n",
    "Sbatch options extend beyond just specifying resources. There are ways you can utulise `sbatch` features to make your life easier or aid in automation:\n",
    "* redirecting where your output and error messages go\n",
    "* changing directory\n",
    "* notifying you of when jobs have started, ended\n",
    "* Submitting Python and R scripts\n",
    "* Making use of Slurm's environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sbatch scripting features cont.\n",
    "\n",
    "### a short aside on `stdout` and `stderr`\n",
    "Linux uses has two main \"channels\" to send output messages to. One is \"stdout\" (standard out), and the other is \"stderr\" (standard error).\n",
    "\n",
    "If you have ever used the `|` `>` or `>>` shell scripting features, then you've _redirected_ `stdout` somewhere else e.g., to another command, a file, or the void (`/dev/null`).\n",
    "\n",
    "```bash\n",
    "$ ls dir-that-doesnt-exist\n",
    "ls: cannot access dir-that-doesnt-exist: No such file or directory # this is a stderr output`\n",
    "```\n",
    "\n",
    "```bash\n",
    "$ ls ~\n",
    "bin cache Desktop Downloads ... # this is a stdout output!\n",
    "```\n",
    "\n",
    "### redirecting output and stderr\n",
    "Sbatch will automatically redirect `stout` and `stdir` to a single file called `slurm-jobid.out`. But this may not be useful. Maybe you want to seperate any \"output\" from \"errors\". This can be done with `--output` and `--error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: module: command not found\n",
      "Fatal error: cannot open file 'matmul.rscript': No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev1-stderrstdout\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --output=results/Rmatmul-%j.out # the %j is interpreted as the job id!\n",
    "#SBATCH --error=logs-debug/Rmatmul-%j.err\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### changing directory\n",
    "The `sbatch` option `--chdir` can make life a bit easier for many reasons:\n",
    "* your script may be \"far\" from your data e.g a seperate scripts folder\n",
    "* you may be processing data in different places\n",
    "\n",
    "A typical approach would be to either modify the `--output` and `--error` locations and use `cd`.\n",
    "\n",
    "`--chdir` changes the working directory _which includes where stderr and stdout goes_\n",
    "\n",
    "This can be more concise and avoids having to change multiple paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: module: command not found\n",
      "Fatal error: cannot open file 'matmul.rscript': No such file or directory\n"
     ]
    },
    {
     "ename": "",
     "evalue": "2",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev2-chdir\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --output=Rmatmul-%j.out\n",
    "#SBATCH --error=Rmatmul-%j.err\n",
    "#SBATCH --chdir=/vast/scratch/yang.e/slurm-demo/test1\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
