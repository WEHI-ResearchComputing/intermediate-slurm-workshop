{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intermediate Slurm on Milton\n",
    "### Delivered by WEHI Research Computing Platform\n",
    "\n",
    "<pre>Edward Yang    Michael Milton    Julie Iskander</pre><br>\n",
    "\n",
    "<img src=\"static/1200px-Slurm_logo.svg.png\" alt=\"Slurm\" width=\"100\"/>\n",
    "<img src=\"static/milton.png\" alt=\"Milton Mascot\" width=\"100\"/>\n",
    "<img src=\"static/WEHI_RGB_logo.png\" alt=\"WEHI logo\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [OPTIONAL SLIDE] Self Introductions!\n",
    "\n",
    "### Me\n",
    "* Civil Engineer by training\n",
    "* HPC by interest\n",
    "* Specialise in parallel programming (MPI, OpenMP, CUDA)\n",
    "* I use HPC to simulate fluid and granular flows\n",
    "* Historically flat-white person, but moving to long Macs\n",
    "\n",
    "## How about you?\n",
    "* name\n",
    "* How you use Milton's HPC\n",
    "* Your coffee/tea order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background\n",
    "* We already ran an \"intro to Slurm\" workshop (recording on RCP website)\n",
    "* More \"advanced\" features of Slurm were highly requested\n",
    "\n",
    "### Target Audience\n",
    "* You've submitted quite a few jobs via `sbatch`\n",
    "* You're familiar with resource requests. Like:\n",
    "    * using `--ntasks` and `--cpus-per-task`\n",
    "    * using `--mem` and/or `--memory-per-cpu`\n",
    "* You're wondering whether your jobs are utilizing resources efficiently\n",
    "* You're wondering how to make your life easier when using `sbatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Background</div>\n",
    "\n",
    "My goal for the session is to teach you how to:\n",
    "* get the status of the cluster\n",
    "* get information about your jobs\n",
    "* make use of `sbatch` scripting features\n",
    "* Run emabarrasingly parallel tasks with job arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda for Today\n",
    "\n",
    "1. <p style=\"color: blue\">Introduction & Housekeeping</p>\n",
    "\n",
    "\n",
    "2. Lunch\n",
    "\n",
    "\n",
    "3. Laying the groundwork: nodes, tasks and other Slurm terminology\n",
    "\n",
    "\n",
    "4. Understanding your jobs and the job queue\n",
    "\n",
    "\n",
    "5. Basic job profiling\n",
    "\n",
    "\n",
    "6. Slurm scripting features\n",
    "\n",
    "\n",
    "7. Embarrasingly parallel workflows with Slurm job arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction and Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Introduction and Housekeeping 1</div>\n",
    "\n",
    "### Format\n",
    "Slides + live coding\n",
    "\n",
    "Live coding will be on Milton, so make sure you're connected to WEHI's VPN or staff network, or use RAP: https://rap.wehi.edu.au\n",
    "\n",
    "Please follow along to reinforce learning!\n",
    "\n",
    "Questions:\n",
    "* Put your hand up whenever you have a question or have an issue running things\n",
    "* Questions in the chat are welcome and will be addressed by helpers\n",
    "\n",
    "Material is available here:\n",
    "* slides: https://wehi-researchcomputing.github.io/intermediate-slurm-workshop\n",
    "* material: https://github.com/WEHI-ResearchComputing/intermediate-slurm-workshop\n",
    "    * the base demo scripts are in `demo-script`. We will build on these during the workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Introduction and Housekeeping 2</div>\n",
    "\n",
    "### Expected understanding of\n",
    "* Understanding of \"resources\" concept<br>\n",
    "    * CPUs\n",
    "    * RAM/memory\n",
    "    * Nodes\n",
    "    * gres (GPUs)\n",
    "\n",
    "\n",
    "* Have used job submission commands\n",
    "    * `srun    # executes a command/script/binary across tasks`\n",
    "    * `salloc  # allocates resources to be used (interactively and/or via srun)`\n",
    "    * `sbatch  # submits a script for later execution on requested resources`\n",
    "\n",
    "\n",
    "* awareness of resource request options\n",
    "    * `--ntasks=             # \"tasks\" recognised by srun`\n",
    "    * `--nodes=              # no. of nodes`\n",
    "    * `--ntasks-per-node=    # tasks per node`\n",
    "    * `--cpus-per-task=      # cpus per task`\n",
    "    * `--mem=                # memory required for entire job`\n",
    "    * `--mem-per-cpu=        # memory required for each CPU`\n",
    "    * `--gres=               # \"general resource\" (i.e. GPUs)`\n",
    "    * `--time=               # requested wall time`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LUNCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laying the Groundwork: Nodes, Tasks and Other Slurm Stuff\n",
    "\n",
    "Reviewing cluster concepts and briefly explaining <strong>tasks</strong> and <strong>job step</strong> Slurm concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 1</div>\n",
    "\n",
    "### What are Nodes?\n",
    "Nodes are essentially standalone computers with their own CPU cores, RAM, local storage, and maybe GPUs. \n",
    "<br>\n",
    "<img src=\"static/node-diagram.png\" alt=\"Node diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 2</div>\n",
    "\n",
    "HPC clusters (or just clusters) will consist of multiple nodes connected together through a (sometimes fast) network. <br>\n",
    "<img src=\"static/cluster-diagram.png\" alt=\"Cluster diagram\" width=\"400\">\n",
    "<img src=\"static/shared-storage-diagram.png\" alt=\"Shared storage diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 3</div>\n",
    "\n",
    "Nodes cannot collaborate on problems unless they are running a programmed designed that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's like clicking your mouse on your PC, and expecting the click to register on a colleague's PC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's possible, but needs a special program/protocol to do so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Biological sciences and statistics tend not to make use of multiple nodes to cooperate on a single problem.\n",
    "\n",
    "Hence, we recommend passing `--nodes=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 4</div>\n",
    "\n",
    "### So why are tasks useful/important?\n",
    "\n",
    "The Slurm task model was created with \"traditional HPC\" in mind\n",
    "* `srun` creates `ntasks` instances of a program which coordinate using MPI\n",
    "* Some applications are designed to use multiple cores per task (hybrid MPI-OpenMP) for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Tasks are not as relevant in bioinformatics, but Slurm nevertheless uses tasks for accounting/profiling purposes. \n",
    "\n",
    "Therefore, it's useful to have an understanding of tasks in order to interpret some of Slurm's job accounting/profiling outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 5</div>\n",
    "\n",
    "### What are tasks?\n",
    "Tasks are a collection of resources (CPU cores, GPUs) expected to perform the same \"task\", or used by a single program e.g., via threads, Python multiprocessing, or OpenMP.\n",
    "<img src=\"static/tasks-diagram1.png\" alt=\"Tasks diagram\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 6</div>\n",
    "\n",
    "A task can only be given resources co-located on a node. <br>\n",
    "Multiple tasks requested by `sbatch` or `salloc` can be spread across multiple nodes (unless `--nodes=` is specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if we have two nodes with 4 CPU cores each:\n",
    "\n",
    "requesting 1 task and 8 cpus-per-task won't work.\n",
    "\n",
    "But requesting 2 tasks and 4 cpus-per-task will!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most data science, statistics, bionformatics, health-science work will use `--ntasks=1`, and using `--cpus-per-task`. \n",
    "\n",
    "If you see/hear anything to do with \"distributed\" or MPI (e.g. distributed ML), you may want to change these options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Nodes, Tasks and Other Slurm Stuff 7</div>\n",
    "\n",
    "### A review of launching jobs (`srun` vs `sbatch` and `salloc`)\n",
    "\n",
    "TL;DR:\n",
    "* `sbatch` requests resources for use with a script\n",
    "* `salloc` requests resources to be used interactively\n",
    "* `srun` runs programs/scripts using resources requested by `sbatch` and `salloc`\n",
    "    * When run \"inside\" a job, `srun` will use the resources requested in the parent request\n",
    "    * When run \"outside\" a job, `srun` will need to be passed the resource request e.g. `--ntasks`\n",
    "\n",
    "`srun` will execute `ntasks` instances of the same command/script/program. e.g.,\n",
    "\n",
    "`srun echo hello world` will run `echo` equal to the number of tasks requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Monitoring Your Jobs and the Job Queue\n",
    "\n",
    "Using Slurm and system tools to understand what your jobs are doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 1</div>\n",
    "Slurm has lots of data on your jobs and the cluster!\n",
    "\n",
    "Primary utilities discussed in this section:\n",
    "* `squeue`    _Live_ Job queue data\n",
    "* `scontrol`  _Live_ Singular job data\n",
    "* `sinfo`     _Live_ Cluster data\n",
    "\n",
    "This section show you how to get more detailed information about:\n",
    "* the queue,\n",
    "* other jobs in the queue, and\n",
    "* the state/business of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 2</div>\n",
    "\n",
    "### Building on the basics: `squeue`\n",
    "\n",
    "`squeue` shows everyone's job in the queue (passing `-u <username>`) shows only `<username>`'s jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           8516030      gpuq interact bollands  R    1:30:11      1 gpu-p100-n01\n",
      "           8515707      gpuq cryospar cryospar  R    3:04:59      1 gpu-p100-n01\n",
      "           8511988 interacti sys/dash    yan.a  R   20:15:53      1 sml-n03\n",
      "           8516092 interacti     work jackson.  R    1:21:42      1 sml-n01\n"
     ]
    }
   ],
   "source": [
    "squeue | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 3</div>\n",
    "Getting a bit more: `squeue --long` makes things more legible adds the \"time_limit\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 03 12:57:40 2022\n",
      "             JOBID PARTITION     NAME     USER    STATE       TIME TIME_LIMI  NODES NODELIST(REASON)\n",
      "           8649808 gpuq_larg   AF2.2g iskander  RUNNING    4:34:07 5-00:00:00      1 gpu-a100-n02\n",
      "           8649805 gpuq_larg   AF2.2g iskander  RUNNING 1-03:47:14 5-00:00:00      1 gpu-a100-n01\n",
      "           8664606 interacti sys/dash     wu.y  RUNNING    2:12:59   8:00:00      1 med-n01\n"
     ]
    }
   ],
   "source": [
    "squeue --long | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 4</div>\n",
    "\n",
    "But what if we want _even more_ information?\n",
    "\n",
    "We have to make use of the formatting options!\n",
    "\n",
    "```\n",
    "$ squeue --Format field1,field2,...\n",
    "```\n",
    "\n",
    "OR use the environment variable `SQUEUE_FORMAT2`. Useful fields:\n",
    "\n",
    "| Resources related | Time related | Scheduling   |\n",
    "| :---              | :---         | :---         |\n",
    "| `NumCPUs`         | `starttime`  | `JobId`      |\n",
    "| `NumNodes`        | `submittime` | `name`       |\n",
    "| `minmemory`       | `pendingtime`| `partition`  |\n",
    "| `tres-alloc`      | `timelimit`  | `priority`   |\n",
    "| `minmemory`       | `timeleft`   | `reasonlist` |\n",
    "|                   | `timeused`   | `workdir`    |\n",
    "|                   |              | `state`      |\n",
    "\n",
    "You can always use `man squeue` to see the entire list of options.\n",
    "\n",
    "So you don't have to type out the fields, I recommend aliasing the the command with your fields of choice in `~/.bashrc` e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 5</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   NAME   PARTITION  ST TRES_ALLOC                                                  TIME_LIMIT  TIME_LEFT   \n",
      "8517002 R      bigmem     R  cpu=22,mem=88G,node=1,billing=720984                        1-00:00:00  23:35:18    \n",
      "8516030 intera gpuq       R  cpu=2,mem=20G,node=1,billing=44,gres/gpu=1,gres/gpu:p100=1  8:00:00     4:43:00     \n",
      "8515707 cryosp gpuq       R  cpu=8,mem=17G,node=1,billing=44,gres/gpu=1,gres/gpu:p100=1  2-00:00:00  1-19:08:12  \n",
      "8511988 sys/da interactiv R  cpu=8,mem=16G,node=1,billing=112                            1-00:00:00  1:57:18     \n"
     ]
    }
   ],
   "source": [
    "alias sqv=\"squeue --Format=jobid:8,name:6' ',partition:10' ',statecompact:3,tres-alloc:60,timelimit:12,timeleft:12\"\n",
    "sqv | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   NAME   PARTITION  ST TRES_ALLOC                                                  TIME_LIMIT  TIME_LEFT   \n",
      "8516851 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516850 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516849 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n",
      "8516848 bionix regular    PD cpu=24,mem=90G,node=1,billing=204                           2-00:00:00  2-00:00:00  \n"
     ]
    }
   ],
   "source": [
    "sqv -u bedo.j | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 6</div>\n",
    "\n",
    "### Getting detailed information of your running/pending job\n",
    "\n",
    "`scontrol show job <jobid>`\n",
    "\n",
    "Useful if you care only about a specific job.\n",
    "\n",
    "It's very useful when debugging jobs.\n",
    "\n",
    "A lot of information without needing lots of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId=8516360 JobName=Extr16S23S\n",
      "   UserId=woodruff.c(2317) GroupId=allstaff(10908) MCS_label=N/A\n",
      "   Priority=324 Nice=0 Account=wehi QOS=normal\n",
      "   JobState=RUNNING Reason=None Dependency=(null)\n",
      "   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0\n",
      "   RunTime=00:21:53 TimeLimit=2-00:00:00 TimeMin=N/A\n",
      "   SubmitTime=2022-10-20T11:37:49 EligibleTime=2022-10-20T11:37:49\n",
      "   AccrueTime=2022-10-20T11:37:49\n",
      "   StartTime=2022-10-20T14:28:03 EndTime=2022-10-22T14:28:03 Deadline=N/A\n",
      "   PreemptEligibleTime=2022-10-20T14:28:03 PreemptTime=None\n",
      "   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-10-20T14:28:03 Scheduler=Main\n",
      "   Partition=regular AllocNode:Sid=vc7-shared:12938\n",
      "   ReqNodeList=(null) ExcNodeList=(null)\n",
      "   NodeList=med-n24\n",
      "   BatchHost=med-n24\n",
      "   NumNodes=1 NumCPUs=32 NumTasks=32 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n",
      "   TRES=cpu=32,mem=48G,node=1,billing=128\n",
      "   Socks/Node=* NtasksPerN:B:S:C=32:0:*:* CoreSpec=*\n",
      "   MinCPUsNode=32 MinMemoryNode=48G MinTmpDiskNode=0\n",
      "   Features=(null) DelayBoot=00:00:00\n",
      "   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n",
      "   Command=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/ribosomal_16S23S_extract_singlespecies.sh Staphylococcus epidermidis 32\n",
      "   WorkDir=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell\n",
      "   StdErr=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/slurm-8516360.out\n",
      "   StdIn=/dev/null\n",
      "   StdOut=/stornext/Bioinf/data/lab_speed/cjw/microbiome/scripts/shell/slurm-8516360.out\n",
      "   Power=\n",
      "   MailUser=woodruff.c@wehi.edu.au MailType=END,FAIL\n",
      "   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "scontrol show job 8516360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\"> Monitoring Your jobs and the Job Queue 7</div>\n",
    "\n",
    "### Monitoring the cluster\n",
    "\n",
    "Being able to understand the state of the cluster, can help understand why your job might be waiting.\n",
    "\n",
    "Or, you can use the information to your advantage to reduce wait times.\n",
    "\n",
    "To view the state of the cluster, we're going to use the `sinfo` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTITION        AVAIL  TIMELIMIT  NODES  STATE NODELIST\n",
      "interactive         up 1-00:00:00      4    mix med-n03,sml-n[01-03]\n",
      "interactive         up 1-00:00:00      1  alloc med-n02\n",
      "interactive         up 1-00:00:00      1   idle med-n01\n",
      "regular*            up 2-00:00:00     42    mix lrg-n[02-03],med-n[03-05,07-09,12-13,18,20-23,25-27,29-30],sml-n[02-20,22-24]\n",
      "regular*            up 2-00:00:00     13  alloc lrg-n04,med-n[02,06,10-11,14-17,19,24,28],sml-n21\n",
      "long                up 14-00:00:0     40    mix med-n[03-05,07-09,12-13,18,20-23,25-27,29-30],sml-n[02-20,22-24]\n",
      "long                up 14-00:00:0     12  alloc med-n[02,06,10-11,14-17,19,24,28],sml-n21\n",
      "bigmem              up 2-00:00:00      3    mix lrg-n02,med-n[03-04]\n",
      "bigmem              up 2-00:00:00      1  alloc med-n02\n",
      "bigmem              up 2-00:00:00      1   idle lrg-n01\n",
      "gpuq                up 2-00:00:00      1    mix gpu-p100-n01\n",
      "gpuq                up 2-00:00:00     11   idle gpu-a30-n[01-07],gpu-p100-n[02-05]\n",
      "gpuq_interactive    up   12:00:00      1    mix gpu-a10-n01\n",
      "gpuq_large          up 2-00:00:00      3   idle gpu-a100-n[01-03]\n"
     ]
    }
   ],
   "source": [
    "sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 8</div>\n",
    "Like `squeue`, we can augment `sinfo`'s behaviour with options.\n",
    "\n",
    "A very useful option is to use the `-N` (N for nodes) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELIST      NODES        PARTITION STATE \n",
      "gpu-a10-n01       1 gpuq_interactive mix   \n",
      "gpu-a30-n01       1             gpuq idle  \n",
      "gpu-a30-n02       1             gpuq idle  \n",
      "gpu-a30-n03       1             gpuq idle  \n"
     ]
    }
   ],
   "source": [
    "sinfo -N | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And now the data is now node-oriented instead of partition oriented!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Monitoring Your Jobs and the Job Queue 9</div>\n",
    "But just knowing whether nodes are \"idle\", \"mixed\", or \"allocated\" is not the _most useful_ information.\n",
    "\n",
    "We can add detail with formatting options as well.\n",
    "\n",
    "| CPU | memory | gres (GPU) | node state | time |\n",
    "| :---| :--- | :--- | :--- | :--- |\n",
    "| `CPUsState` | `FreeMem` | `GresUsed` | `StateCompact` | `Time` |\n",
    "| | `AllocMem` | `Gres` | | |\n",
    "| | `Memory` | | | |\n",
    "\n",
    "* CPUs occupied/available/total: CPUsState\n",
    "* memory occupied/available/total: FreeMem, AllocMem, Memory\n",
    "* gres (GPU) occupied/available: GresUsed, Gres\n",
    "* State of the node (e.g. whether the node is down): StateCompact\n",
    "* Max time: Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NODELIST    PARTITION  CPUS(A/I/O/T) FREE_MEM MEMORY   GRES_USED           GRES       STATE   TIMELIMIT           \n",
      "gpu-a10-n01 gpuq_inter 0/48/0/48     163914   257417   gpu:A10:0(IDX:N/A)  gpu:A10:4  idle    12:00:00            \n",
      "gpu-a30-n01 gpuq       0/96/0/96     450325   511362   gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n",
      "gpu-a30-n02 gpuq       0/96/0/96     436435   511362   gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n",
      "gpu-a30-n03 gpuq       0/96/0/96     497816   511362   gpu:A30:0(IDX:N/A)  gpu:A30:4  idle    2-00:00:00          \n"
     ]
    }
   ],
   "source": [
    "sinfo -NO nodelist:11' ',partition:10' ',cpusstate:13' ',freemem:8' ',memory:8' ',gresused,gres:11,statecompact:8,time | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Monitoring Your Jobs and the Job Queue 10</div>\n",
    "\n",
    "For newer Slurm versions, the GUI tool `sview` is an option.\n",
    "\n",
    "It's functionality is currently a little limited and not customizable.\n",
    "\n",
    "Requires and X11 server running on your computer (Windows: MobaXTerm, Mac: XQuartz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(sview:4266): Gtk-\u001b[1;33mWARNING\u001b[0m **: \u001b[34m16:00:18.949\u001b[0m: cannot open display: \n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Job Monitoring and Profiling\n",
    "\n",
    "Using command-line tools to obtain visibility into how your job is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 1</div>\n",
    "\n",
    "This section will look at using command-line tools to obtain visibility into how your job is performing.\n",
    "\n",
    "| type of data | Live | Historical |\n",
    "| --- | --- | --- |\n",
    "| <strong>good for</strong> | debugging | debugging |\n",
    "| | evaluating utilization | profiling |\n",
    "| <strong>drawbacks</strong> | uses system tools, so requires some system understanding | Only provides data when jobs are completed |\n",
    "\n",
    "We will look at:\n",
    "* `htop` for _Live_ Process activity on nodes\n",
    "* `nvidia-smi` for _Live_ GPU activity on nodes\n",
    "* `seff` for _Historical_ job CPU and memory usage data\n",
    "* `dcgmstats` for _Historical_ job GPU usage data\n",
    "* `sacct` for _Historical_ job data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 2</div>\n",
    "\n",
    "### Live monitoring of jobs\n",
    "\n",
    "Slurm can't provide accurate \"live\" data about jobs' activities\n",
    "\n",
    "System tools must be used instead.\n",
    "\n",
    "This requires matching jobs to processes on a node with `squeue` and `ssh`.\n",
    "\n",
    "A bit of system understanding is also needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 3</div>\n",
    "\n",
    "#### Live monitoring: CPU, memory, IO activity\n",
    "`htop` is a utility often installed on HPC clusters for monitoring processes.\n",
    "\n",
    "It can be used to look at the CPU, memory, and IO utilization of a running process. \n",
    "\n",
    "It's not a Slurm tool, but is nevertheless very useful in monitoring jobs' activity and diagnosing issues.\n",
    "\n",
    "To show only your processes, execute `htop -u $USER`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 4</div>\n",
    "\n",
    "`htop` shows the individual CPU core utilization on the top, followed by memory utilization and some misc. information.\n",
    "\n",
    "The bottom panel shows the process information\n",
    "\n",
    "Relevant Headings:\n",
    "* USER: User that owns the process\n",
    "* PID: Process ID\n",
    "* %CPU: % of a single core that a process is using e.g. 400% means process is using 4 cores\n",
    "* %MEM: % of node's total RAM that process is using\n",
    "* VSZ: \"Virtual\" memory (bytes) - the memory a process \"thinks\" it's using\n",
    "* RSS: \"Resident\" memory (bytes) - the actual physical memory a process is using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 5</div>\n",
    "You can organize the process information into \"trees\" by pressing `F5`\n",
    "\n",
    "You can add IO information by\n",
    "1. Press `F2` (Setup)\n",
    "2. Press down three times to move the cursor to \"Columns\" and press right twice\n",
    "3. The cursor should now be in \"Available Columns\". Scroll down to `IO_READ_RATE` and press enter\n",
    "4. Scroll down to `IO_WRITE_RATE` and press enter\n",
    "5. Press `F10` to exit. \n",
    "You should now be able to see read/write rates for processes that you have permissions for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<strong>Tips</strong>: \n",
    "* `htop` configurations are saved in `~/.config/htop`. Delete this folder to reset your `htop` conifguration.\n",
    "* `ps` and `pidstat` are useful alternatives which can be incorporated into scripts.\n",
    "* Some systems may not have `htop` installed, in which case `top` can be used instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 6</div>\n",
    "\n",
    "#### Live monitoring: GPU activity\n",
    "\n",
    "To monitor activity of Milton's NVIDIA GPUs, we must rely on NVIDIA's `nvidia-smi` tool.\n",
    "\n",
    "`nvidia-smi` shows information about the memory and compute utilization, process allocation and other details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Like `htop`, `nvidia-smi` only provides information on processes running on a GPU. If your job is occupying an entire node and all its GPUs, it should be straightforward to determine which GPUs you've been allocated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But if your job is sharing a node with other jobs, you might not know straight away which GPU your job has been allocated. You can determine this by\n",
    "* inferring by the command being run on a GPU, or\n",
    "* using `squeue` with extra formatting options as discussed previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<strong>Note</strong>:\n",
    "This tool is available only on GPU nodes where the CUDA drivers are installed, so you must `ssh` to a `gpu` node to try it.\n",
    "\n",
    "<strong>Tip</strong>: Combine `nvidia-smi` with `watch` to automatically update the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 7</div>\n",
    "\n",
    "### Historical monitoring of jobs\n",
    "Slurm tools and plugins are generally easier to use because they provide information on a per-job basis, meaning there's no need to match processes with jobs like previously discussed.\n",
    "\n",
    "<strong>Tips</strong>: _generally_, results are more reliable when executing commands with `srun`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 8</div>\n",
    "\n",
    "#### Historical data: CPU and memory utilization\n",
    "The `seff` command shows the memory and CPU utilization of a job that has <strong>ended</strong>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 8665813\n",
      "Cluster: milton\n",
      "User/Group: yang.e/allstaff\n",
      "State: COMPLETED (exit code 0)\n",
      "Nodes: 1\n",
      "Cores per node: 4\n",
      "CPU Utilized: 00:09:04\n",
      "CPU Efficiency: 99.27% of 00:09:08 core-walltime\n",
      "Job Wall-clock time: 00:02:17\n",
      "Memory Utilized: 1.95 GB (estimated maximum)\n",
      "Memory Efficiency: 48.83% of 4.00 GB (1.00 GB/core)\n"
     ]
    }
   ],
   "source": [
    "seff 8665813"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 9</div>\n",
    "\n",
    "`sacct` is a general job history querying command-line tool that can provide lots of information about your _past_ jobs.\n",
    "\n",
    "<strong>Note</strong>: `sacct` data can take a few minutes to be updated, so is best for jobs that have finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following `sacct` command shows your job data for jobs since 1st Nov:\n",
    "* Job steps' ID and name\n",
    "* Requested resources\n",
    "* Elapsed time\n",
    "* The quantity of data written and read\n",
    "* The quantity of virtual and resident memory used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the IO and memory values shown will be for the highest use <strong>task</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 10</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         JobID    JobName NCPUS        NodeList    Elapsed      State  MaxDiskRead MaxDiskWrite  MaxVMSize     MaxRSS \n",
      "-------------- ---------- ----- --------------- ---------- ---------- ------------ ------------ ---------- ---------- \n",
      "       8664599 sys/dashb+     2         sml-n01 1-00:00:22    TIMEOUT                                                 \n",
      " 8664599.batch      batch     2         sml-n01 1-00:00:23  CANCELLED      102.64M       15.11M   1760920K     99812K \n",
      "8664599.extern     extern     2         sml-n01 1-00:00:22  COMPLETED        0.00M            0    146612K        68K \n"
     ]
    }
   ],
   "source": [
    "sacct -S 2022-11-01 -o jobid%14' ',jobname,ncpus%5' ',nodelist,elapsed,state,maxdiskread,maxdiskwrite,maxvmsize,maxrss | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 11</div>\n",
    "\n",
    "### A short aside on job _steps_\n",
    "Slurm breaks jobs into steps. Jobs will have steps:\n",
    "* `.extern`: work done not part of the job i.e. overhead\n",
    "* `.<index>`: work done with `srun`\n",
    "* `.batch`: work inside an `sbatch` script, but not executed by `srun`\n",
    "* `.interactive`: work done inside an interactive `salloc` session, but not executed by `srun`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 12</div>\n",
    "\n",
    "#### Historical data: GPU activity\n",
    "By default, Slurm doesn't have the ability to produce stats on GPU usage.\n",
    "\n",
    "WEHI's ITS have implemented the `dcgmstats` NVIDIA Slurm plugin which can produce these summary stats.\n",
    "\n",
    "To use this plugin, pass the `--comment=dcgmstats` option to `srun`, `salloc`, or `sbatch`.\n",
    "\n",
    "If your job requested at least one GPU, an extra output file will be generated in the working directory called `dcgm-stats-<jobid>.out`. The output file will contain a table for each GPU requested by the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Basic Job Monitoring and Profiling 13</div>\n",
    "\n",
    "### Summary\n",
    "* live monitoring:\n",
    "    * `htop` for CPU, memory, and IO data (requires configuration)\n",
    "    * `nvidia-smi` for GPU activity\n",
    "    * both require matching jobs to hardware and running processes\n",
    "* historical monitoring:\n",
    "    * `seff` command for simple CPU and memory utilization data for one job\n",
    "    * `sacct` command for memory and IO data for multiple past jobs\n",
    "    * `dcgmstats` Slurm plugin for GPU stats for a single Slurm job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sbatch Scripting Features\n",
    "Taking advantage of lesser-known options and environment features to make life easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 1</div>\n",
    "Sbatch scripts have a lot of nice features that extend beyond requesting resources. This section will look at some of these useful features which you can use in your workflows.\n",
    "\n",
    "This section will look at:\n",
    "* getting email notifications\n",
    "* changing `stdout` and `stderr` files\n",
    "* controlling how jobs depend on each other\n",
    "* making use of job environments and interpreters (e.g. python or R)\n",
    "* submitting `sbatch` scripts without a script\n",
    "\n",
    "We're going to start with a simple R script submitted by wrapper sbatch script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 2</div>\n",
    "\n",
    "```r\n",
    "## matmul.rscript\n",
    "# multiplies two matrices together and prints how long it takes.\n",
    "\n",
    "print(\"starting the matmul R script!\")\n",
    "nrows = 1e3\n",
    "print(paste0(\"elem: \", nrows, \"*\", nrows, \" = \", nrows*nrows))\n",
    "\n",
    "# generating matrices\n",
    "M <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "N <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "\n",
    "# start matmul\n",
    "start.time <- Sys.time()\n",
    "invisible(M %*% N)\n",
    "end.time <- Sys.time()\n",
    "\n",
    "# Getting final time and writing to stdout\n",
    "elapsed.time <- difftime(time1=end.time, time2=start.time, units=\"secs\")\n",
    "print(elapsed.time)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"starting the matmul R script!\"\n",
      "[1] \"elem: 1000*1000 = 1e+06\"\n",
      "Time difference of 0.06260109 secs\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "## submit-matmul.sh\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev0\n",
    "\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 4</div>\n",
    "\n",
    "### Email notifications\n",
    "Getting notifications about the status of your Slurm jobs remove the need to `ssh` onto Milton and running `squeue` to get the status of your jobs.\n",
    "\n",
    "Instead, it will notify you when your job state has changed e.g. when it has started or ended.\n",
    "\n",
    "To enable this behaviour, add the following options to your job scripts:\n",
    "```\n",
    "--mail-user=me@gmail.com\n",
    "--mail-type=ALL\n",
    "```\n",
    "This sends emails to `me@gmail.com` when the job state changes. \n",
    "\n",
    "If you only want to know when your job goes through certain states, e.g. if it fails or is pre-empted but not when it starts or finishes:\n",
    "* BEGIN: job starts\n",
    "* END: job finishes successfully\n",
    "* FAIL: job fails\n",
    "* TIME_LIMIT: job reaches time limit\n",
    "* TIME_LIMIT_50/80/90: job reaches 50%/80%/90% of time limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 5</div>\n",
    "\n",
    "```r\n",
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev1 - email notifications\n",
    "\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mail-user=yang.e@wehi.edu.au\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 6</div>\n",
    "\n",
    "### `sbatch` without a script\n",
    "In some cases, one may wish to submit singular commands to the scheduler. `srun` and `salloc` can do this, but they need a terminal attached i.e., if you close your terminal with the `srun` or `salloc` session, then the job fails.\n",
    "\n",
    "the `sbatch --wrap` option allows you to submit a singular command instead of an entire script.\n",
    "\n",
    "This can be useful for testing, or implementing `sbatch` inside a script that manages your workflow.\n",
    "\n",
    "Note that `sbatch --wrap` infers which interpreter to use from your active environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 7</div>\n",
    "\n",
    "### a short aside on `stdout` and `stderr`\n",
    "Linux uses has two main \"channels\" to send output messages to. One is \"stdout\" (standard out), and the other is \"stderr\" (standard error).\n",
    "\n",
    "If you have ever used the `|` `>` or `>>` shell scripting features, then you've _redirected_ `stdout` somewhere else e.g., to another command, a file, or the void (`/dev/null`).\n",
    "\n",
    "```bash\n",
    "$ ls dir-that-doesnt-exist\n",
    "ls: cannot access dir-that-doesnt-exist: No such file or directory # this is a stderr output`\n",
    "```\n",
    "\n",
    "```bash\n",
    "$ ls ~\n",
    "bin cache Desktop Downloads ... # this is a stdout output!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 8</div>\n",
    "\n",
    "### Redirecting job's `stderr` and `stdout`\n",
    "By default:\n",
    "* job's working directory is the directory you submitted from\n",
    "* `stdout` is directed to `slurm-<jobid>.out` in the job's working directory\n",
    "* `stderr` is directed to wherever `stdout` is directed to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Redirect `stderr` and `stdout` with `--error` and `--output` options. They work with both relative and absolute paths, e.g.\n",
    "```\n",
    "--error=/dev/null\n",
    "--output=path/to/output.out\n",
    "```\n",
    "where paths are resolved relative to the job's working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Variables can be used, like:\n",
    "* `%j`: job ID\n",
    "* `%x`: job name\n",
    "* `%u`: username\n",
    "* `%t`: task ID i.e., seperate file per task\n",
    "* `%N`: node name i.e., seperate file per nodes in job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch Scripting Features 9</div>\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# Example sbatch script running Rscript\n",
    "# Does a matmul\n",
    "# rev2 - added --output and --error options\n",
    "\n",
    "#SBATCH --mem=8G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --time=1-\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mail-user=yang.e@wehi.edu.au\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --output=logs/matmul-%j.out\n",
    "#SBATCH --error=logs-debug/matmul-%j.err\n",
    "\n",
    "# loading module for R\n",
    "module load R/openBLAS/4.2.1\n",
    "\n",
    "Rscript matmul.rscript\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 10</div>\n",
    "\n",
    "### Using job dependancies\n",
    "Slurm allows for submitted jobs to wait for another job to start or finish before beginning. While probably not as effective as workflow managers like Nextflow, Slurm's job dependencies can still be useful for simple workflows.\n",
    "\n",
    "Make a job dependant on another by passing the `--dependency` option with one of the following values:\n",
    "* `afterok:jobid1:jobid2...` waits for `jobid1`, `jobid2` ... to complete successfully\n",
    "* `afterany:jobid1:jobid2...` \"                              \" to finish (fail, complete, cancelled)\n",
    "* `after:jobid1:jobid2...` \"                                 \" to start or are cancelled.\n",
    "\n",
    "e.g. `--dependency=afterok:12345678` will make the job wait for job `12345678` to complete successfully before starting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 11</div>\n",
    "\n",
    "### Job dependancies example: Recursive jobs\n",
    "Recursive jobs are _one_ way to work with short QOS time limits.\n",
    "\n",
    "Multiple Slurm jobs are submitted with a sequential dependancy pattern, i.e., the second job depends on the first, the third job depends on the second and so on...\n",
    "\n",
    "Slurm script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=2\n",
      "#SBATCH --mem-per-cpu=2G\n",
      "#SBATCH --time=1\n",
      "sleep 10\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/recursive-job.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 12</div>\n",
    "We could submit the Slurm script using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8703619\n",
      "8703620\n",
      "8703621\n",
      "8703622\n",
      "8703623\n",
      "8703624\n",
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           8703594 gpuq_larg interact   yang.e  R      21:18      1 gpu-a100-n01\n",
      "           8701908 interacti sys/dash   yang.e  R    2:07:28      1 sml-n01\n",
      "           8703624   regular test-rec   yang.e PD       0:00      1 (Dependency)\n",
      "           8703623   regular test-rec   yang.e PD       0:00      1 (Dependency)\n",
      "           8703622   regular test-rec   yang.e PD       0:00      1 (Dependency)\n",
      "           8703621   regular test-rec   yang.e PD       0:00      1 (Dependency)\n",
      "           8703620   regular test-rec   yang.e PD       0:00      1 (Dependency)\n",
      "           8703619   regular test-rec   yang.e  R       0:00      1 sml-n05\n",
      "           8703616   regular test-rec   yang.e  R       0:22      1 sml-n02\n"
     ]
    }
   ],
   "source": [
    "# cell to run recursive script\n",
    "prereq_jobid=$(sbatch --parsable demo-scripts/recursive-job.sh)\n",
    "echo $prereq_jobid\n",
    "for i in {1..5}; do\n",
    "    prereq_jobid=$(sbatch --parsable --dependency=afterok:$prereq_jobid demo-scripts/recursive-job.sh)\n",
    "    echo $prereq_jobid\n",
    "done\n",
    "squeue -u $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 13</div>\n",
    "Breaking down the loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. `prereq_jobid=$(sbatch --parsable demo-scripts/recursive-job.sh)`\n",
    "    * Initial submit of recursive-job.sh\n",
    "    * uses the `--parsable` option to get the job id from `sbatch`\n",
    "    * the returned jobid is saved as `prereq_jobid`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. `for i in {1..5}; do`\n",
    "    * a bash `for` loop that loops through 1 to 5, where i is the looping variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. `prereq_jobid=$(sbatch --parsable --dependency=afterok:${prereq_jobid} demo-scripts/recursive-job.sh`\n",
    "    * similar to 1.\n",
    "    * adds the `--dependency=afterok:${prereq_jobid}` option to link jobs\n",
    "    * `afterany` may be preferred instead of `afterok`\n",
    "    * the newly submitted jobid overwrites the `prereq_jobid` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 14</div>\n",
    "\n",
    "### Making use of job environments and interpreters\n",
    "By default, when you submit a Slurm job, Slurm copies all the environment variables in your environment and adds some extra for the job to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "export VAR1=\"here is some text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "echo $VAR1\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/env-vars1.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8681656\n"
     ]
    }
   ],
   "source": [
    "sbatch demo-scripts/env-vars1.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is some text\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8681656.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<strong>Note</strong>: For reproducibility reasons, a Slurm script that relies on environment variables can be submitted inside a wrapper script which first exports the relevant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 15</div>\n",
    "Alternatively, you can use the `--export` option which allows you to set specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is some text\n"
     ]
    }
   ],
   "source": [
    "echo $VAR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8681761\n"
     ]
    }
   ],
   "source": [
    "sbatch --export=VAR1=\"this is some different text\" demo-scripts/env-vars1.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is some different text\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8681761.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This feature is especially useful when submitting jobs inside wrapper scripts.\n",
    "\n",
    "You can also use the `--export-file` option to specify a file with a list of `VAR=value` pairs that you wish the script to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 16</div>\n",
    "Slurm also adds environment variables that enable job parameters use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=2\n",
      "\n",
      "echo I am running on ${SLURM_NODELIST}\n",
      "echo with ${SLURM_NTASKS} tasks\n",
      "echo and ${SLURM_CPUS_PER_TASK} CPUs per task\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/env-vars2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 8681710\n"
     ]
    }
   ],
   "source": [
    "sbatch demo-scripts/env-vars2.sbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am running on sml-n03\n",
      "with 1 tasks\n",
      "and 2 CPUs per task\n"
     ]
    }
   ],
   "source": [
    "cat slurm-8681710.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These Slurm environment variables make it easy to supply parallelisation parameters to a program e.g. specifying number of threads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 17</div>\n",
    "\n",
    "### Submitting scripts with different interpreters\n",
    "Typically scripts submitted by `sbatch` use the `bash` or `sh` interpreter (e.g. `#!/bin/bash`), but it may be more convenient to use a different interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can do this by changing the \"hash bang\" statement at the top of the script. To demonstrate this, we can take our original R matmul script, and add a \"hash bang\" statement to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "## matmul.rscript\n",
      "\n",
      "print(\"starting the matmul R script!\")\n",
      "nrows = 1e3\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/matmul-interpreter1.rscript | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The statement in the above looks for the Rscript in your current environment. This statement only works because Slurm will copy your environment when a Slurm script is submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`python` works similarly. Replace `Rscript` in the hash bang statement to `python`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Alternatively, you can specify the absolute path to the interpreter.\n",
    "\n",
    "e.g. `#!/stornext/System/data/apps/R/openBLAS/R-4.2.1/lib64/R/bin/Rscript`\n",
    "\n",
    "<strong>Tip</strong>: you can use `--export=R_LIBS_USER=...` to point Rscript to your libraries (or `PYTHONPATH` for python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style='text-align: right'>Sbatch scripting features 18</div>\n",
    "Changing the interpreter still allows you to access the extra Slurm environment variables, but in a way appropriate to the interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "R example:<br>\n",
    "```r\n",
    "slurmtasks <- Sys.getenv(\"SLURM_NTASKS\")\n",
    "```\n",
    "\n",
    "Python example:\n",
    "```python\n",
    "import os\n",
    "slurmtasks = os.getenv('SLURM_NTASKS')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Excercise:\n",
    "Add a \"using \\<ntasks> tasks and \\<cpus-per-task> CPUs per task\" statement to the matmul R script. Submit the script to confirm it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The output should look something like:\n",
    "```\n",
    "[1] \"starting the matmul R script!\"\n",
    "[1] \"using 1 tasks and 2 CPUs per task\"\n",
    "[1] \"elem: 1000*1000 = 1e+06\"\n",
    "Time difference of 0.06340098 secs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Embarrasingly Parallel Workflows\n",
    "Making life easier with job arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 1</div>\n",
    "\n",
    "### Embarrasingly Parallel jobs\n",
    "Embarrasingly parallel computation is computation that can occur in parallel with minimal coordination. This type of parallel computation is _very_ common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples are parameter scans, genomic sequencing, basecalling, folding@home ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Embarassingly parallel problems are facilitated in Slurm by \"array jobs\". Array jobs allows you to use a single script to submit multiple jobs with similar functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The main benefits to using an array job are:\n",
    "* they are easier to program\n",
    "    * each array job is grouped under a single job ID and distinguished by array indices e.g. 1234567_1, 1234567_2, ...\n",
    "    * no need for wrapper scripts/loops\n",
    "    * can make use of Slurm environment variables to coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Slurm handles large array jobs better than many individual jobs\n",
    "    * helps the Slurm process the queue faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 2</div>\n",
    "\n",
    "### Setting up an array job\n",
    "Array jobs are created by adding the `--array=start-end` option. Slurm jobs, AKA \"tasks\", will be created with indices between `start` and `end`. e.g. `--array=1-10` will create tasks with indices 1, 2, ..., 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`start` and `end` values can be within 0 and 1000 (inclusive). Note this is site specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Singular values or discrete lists can also be specific e.g. `--array=1` or `--array=1,3,5,7-10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=2\n",
      "#SBATCH --mem=4G\n",
      "#SBATCH --array=1-10\n",
      "\n",
      "## matmul.rscript\n",
      "\n",
      "print(\"starting the matmul R script!\")\n",
      "paste(\"using\", Sys.getenv(\"SLURM_NTASKS\"), \"tasks\")\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/matmul-array1.rscript | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 3</div>\n",
    "\n",
    "### Using array indices in other SBATCH output and error\n",
    "Slurm augments the default output behaviour of array jobs automatically.\n",
    "\n",
    "If no `--output` option is provided, an array job will produce a an output file `slurm-<jobid>-<arrayindex>.out` for each index in the array.\n",
    "\n",
    "If you specify `--output` and `--error`, then you can use `%A` and `%a` variables, which represent the job index and the array index, respectively.\n",
    "\n",
    "e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "#SBATCH --ntasks=1\n",
      "#SBATCH --cpus-per-task=2\n",
      "#SBATCH --mem=4G\n",
      "#SBATCH --array=1-10\n",
      "#SBATCH --output=Rmatmul-times-%A-%a.out\n",
      "#SBATCH --error=Rmatmul-times-%A-%a.err\n",
      "\n",
      "## matmul.rscript\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat demo-scripts/matmul-array2.rscript | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 4</div>\n",
    "\n",
    "### Using array indices in script body\n",
    "Each task in the array can make use of its index to enable parallelism. This is by making use of the `SLURM_ARRAY_TASK_ID` environment variable.\n",
    "\n",
    "Other environment variables are accessible:\n",
    "* `SLURM_ARRAY_JOB_ID` the job Id of the entire job array\n",
    "* `SLURM_ARRAY_TASK_COUNT` the _number_ of tasks in the array\n",
    "* `SLURM_ARRAY_TASK_MAX` the largest ID of tasks in the array\n",
    "* `SLURM_ARRAY_TASK_MIN` the smallest ID of tasks in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Add a paste statement to the matmul R script that prints the task ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The output of each job task should look something like:\n",
    "```\n",
    "[1] \"starting the matmul R script!\"\n",
    "[1] \"using 1 tasks and 2 CPUs per task\"\n",
    "[1] \"I am job task 1 in an array of 10!\"\n",
    "[1] \"elem: 1000*1000 = 1e+06\"\n",
    "Time difference of 0.06340098 secs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```r\n",
    "#!/usr/bin/env Rscript\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --array=1-10\n",
    "#SBATCH --output=Rmatmul-times-%A-%a.out\n",
    "#SBATCH --error=Rmatmul-times-%A-%a.err\n",
    "\n",
    "## matmul.rscript\n",
    "\n",
    "print(\"starting the matmul R script!\")\n",
    "\n",
    "paste(\"using\", Sys.getenv(\"SLURM_NTASKS\"), \n",
    "      \"tasks and\", \n",
    "      Sys.getenv(\"SLURM_CPUS_PER_TASK\"), \n",
    "      \"CPUs per task\")\n",
    "\n",
    "paste(\"I am job task\", \n",
    "      Sys.getenv(\"SLURM_ARRAY_TASK_ID\"), \n",
    "      \"in an array of\", \n",
    "      Sys.getenv(\"SLURM_ARRAY_TASK_COUNT\"))\n",
    "\n",
    "nrows = 1e3\n",
    "print(paste0(\"elem: \", nrows, \"*\", nrows, \" = \", nrows*nrows))\n",
    "\n",
    "# generating matrices\n",
    "M <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "N <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "\n",
    "# start matmul\n",
    "start.time <- Sys.time()\n",
    "invisible(M %*% N)\n",
    "end.time <- Sys.time()\n",
    "\n",
    "# Getting final time and writing to stdout\n",
    "elapsed.time <- difftime(time1=end.time, time2=start.time, units=\"secs\")\n",
    "print(elapsed.time)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 5</div>\n",
    "Excercise: modify the `nrows` variable to equal 10*taskID \n",
    "\n",
    "hint: you will need the `strtoi` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Your output from job task 1 should look like:\n",
    "```\n",
    "[1] \"starting the matmul R script!\"\n",
    "[1] \"using 1 tasks and 2 CPUs per task\"\n",
    "[1] \"I am job task 1 in an array of 10!\"\n",
    "[1] \"elem: 10*10 = 100\"\n",
    "Time difference of 0.06340098 secs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```r\n",
    "#!/usr/bin/env Rscript\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --array=1-10\n",
    "#SBATCH --output=Rmatmul-times-%A-%a.out\n",
    "#SBATCH --error=Rmatmul-times-%A-%a.err\n",
    "\n",
    "## matmul.rscript\n",
    "\n",
    "print(\"starting the matmul R script!\")\n",
    "\n",
    "paste(\"using\", Sys.getenv(\"SLURM_NTASKS\"), \n",
    "      \"tasks and\", \n",
    "      Sys.getenv(\"SLURM_CPUS_PER_TASK\"), \n",
    "      \"CPUs per task\")\n",
    "\n",
    "paste(\"I am job task\", \n",
    "      Sys.getenv(\"SLURM_ARRAY_TASK_ID\"), \n",
    "      \"in an array of\", \n",
    "      Sys.getenv(\"SLURM_ARRAY_TASK_COUNT\"))\n",
    "\n",
    "#nrows = 1e3\n",
    "nrows <- 10 * strtoi(Sys.getenv(\"SLURM_ARRAY_TASK_ID\"))\n",
    "\n",
    "print(paste0(\"elem: \", nrows, \"*\", nrows, \" = \", nrows*nrows))\n",
    "\n",
    "# generating matrices\n",
    "M <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "N <- matrix(rnorm(nrows*nrows),nrow=nrows)\n",
    "\n",
    "# start matmul\n",
    "start.time <- Sys.time()\n",
    "invisible(M %*% N)\n",
    "end.time <- Sys.time()\n",
    "\n",
    "# Getting final time and writing to stdout\n",
    "elapsed.time <- difftime(time1=end.time, time2=start.time, units=\"secs\")\n",
    "print(elapsed.time)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 6</div>\n",
    "\n",
    "For workflows requiring input files or parameters, there are multiple ways you can use job arrays:\n",
    "* folders with job array indices with the necessary input files\n",
    "* programmatically generate CSV file with parameters or paths to files where row/column no. correspond to task IDs\n",
    "* if/else or select case statements in the script\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Handling Embarrasingly Parallel Workflows 7</div>\n",
    "\n",
    "### Job arrays and job dependencies\n",
    "What you can't do:\n",
    "* make job array tasks depend on one another\n",
    "\n",
    "What you can do:\n",
    "* make jobs dependent on entire job arrays\n",
    "    * `--dependency=afterok:<jobid>`\n",
    "* make job arrays dependent on other job/job arrays\n",
    "* make jobs dependent on job array tasks\n",
    "    * `--dependency=afterok:<jobid>_<taskid>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Thanks for attending WEHI's first intermediate Slurm workshop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: right\">Conclusion 1</div>\n",
    "\n",
    "Please fill out our feedback form:\n",
    "\n",
    "<a href=\"https://forms.office.com/pages/responsepage.aspx?id=4nJ8qs_FQEqiKqWFwEygfJ2o16JnCyxPmA6-Ggzd8tNUMEpQUEZGUVRPWFEyNzhSUzE1VDRQQlUyRy4u\">https://forms.office.com/pages/responsepage.aspx?id=4nJ8qs_FQEqiKqWFwEygfJ2o16JnCyxPmA6-Ggzd8tNUMEpQUEZGUVRPWFEyNzhSUzE1VDRQQlUyRy4u</a>\n",
    "\n",
    "We use these forms to help decide which workshops to run in the future and improve our current workshops!\n",
    "\n",
    "\n",
    "Contact us at research.computing@wehi.edu.au for any kind of help related to computing and research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
